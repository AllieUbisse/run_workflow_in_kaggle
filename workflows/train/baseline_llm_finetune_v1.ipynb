{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaxkHI6fCvIF"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JoZlw_MCqQC"
      },
      "outputs": [],
      "source": [
        "def detect_environment():\n",
        "    \"\"\"Return Environment variable (kaggle, colab, local)\n",
        "    \"\"\"\n",
        "    if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
        "        return 'kaggle'\n",
        "    elif 'COLAB_GPU' in os.environ:\n",
        "        return 'colab'\n",
        "    else:\n",
        "        return 'local'\n",
        "\n",
        "def create_workspace_dirs(workspace_path: str):\n",
        "    \"\"\"Setup environment specific workspace directories.\n",
        "\n",
        "       Parameters:\n",
        "       -----------\n",
        "        - workspace_path (str): Path to root workspace environment.\n",
        "\n",
        "       Results:\n",
        "       --------\n",
        "        - CONFIG_PATH - path to all config fiels.\n",
        "        - DATASETS_PATH - path to all datasets.\n",
        "        - MODELS_PATH  - path to all models.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    DATASETS_PATH: str  = os.path.join(workspace_path, 'datasets')\n",
        "    MODELS_PATH: str    = os.path.join(workspace_path, 'models')\n",
        "    CONFIG_PATH: str    = os.path.join(workspace_path, 'config')\n",
        "\n",
        "    # create workspace directories\n",
        "    [os.makedirs(path_var, exist_ok=True) for path_var in [workspace_path,CONFIG_PATH, DATASETS_PATH,MODELS_PATH]]\n",
        "\n",
        "    print(f\"Active working directories:\\n\\n{CONFIG_PATH=}\\n{DATASETS_PATH=}\\n{MODELS_PATH=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3MvCDpBC3YX",
        "outputId": "ac29e945-fe61-425b-929b-dc17333e7148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Active working directories:\n",
            "\n",
            "CONFIG_PATH='/content/workspace/config'\n",
            "DATASETS_PATH='/content/workspace/datasets'\n",
            "MODELS_PATH='/content/workspace/models'\n"
          ]
        }
      ],
      "source": [
        "# Set the development environment variable\n",
        "DEV_ENV: str = detect_environment()\n",
        "\n",
        "# set development workspace directories\n",
        "workspace_path_map: dict = {\n",
        "    \"colab\": \"/content/workspace/\",\n",
        "    \"kaggle\": \"/kaggle/working/workspace/\",\n",
        "    \"local\": \"set_path_to_local/workspace/\" # update this value to local drive\n",
        "                 }\n",
        "\n",
        "create_workspace_dirs(workspace_path_map.get(DEV_ENV))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T20:16:36.819485Z",
          "iopub.status.busy": "2025-04-20T20:16:36.819289Z",
          "iopub.status.idle": "2025-04-20T20:16:36.829311Z",
          "shell.execute_reply": "2025-04-20T20:16:36.828563Z",
          "shell.execute_reply.started": "2025-04-20T20:16:36.819470Z"
        },
        "id": "NYwRarL_dbSG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "CONFIG_PATH='/content/workspace/config'\n",
        "DATASETS_PATH='/content/workspace/datasets'\n",
        "MODELS_PATH='/content/workspace/models'\n",
        "BENCHMARK_PATH= '/content/working/workspace/benchmarks'\n",
        "FINETUNED_MODELS_PATH = os.path.join(MODELS_PATH,'finetuned-model')\n",
        "\n",
        "os.makedirs(BENCHMARK_PATH, exist_ok=True)\n",
        "os.makedirs(FINETUNED_MODELS_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y4Ypt0odbSG"
      },
      "source": [
        "## Setup API secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T21:06:18.607295Z",
          "iopub.status.busy": "2025-04-20T21:06:18.606746Z",
          "iopub.status.idle": "2025-04-20T21:06:18.908970Z",
          "shell.execute_reply": "2025-04-20T21:06:18.908259Z",
          "shell.execute_reply.started": "2025-04-20T21:06:18.607271Z"
        },
        "id": "bWgwTjP_dbSG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if  DEV_ENV.__contains__(\"kaggle\"):\n",
        "   from kaggle_secrets import UserSecretsClient\n",
        "   user_secrets = UserSecretsClient()\n",
        "\n",
        "   # get secret keys\n",
        "   wandb_api_key = user_secrets.get_secret(\"wandb-kenya-clinical-reasoning-key\")\n",
        "   huggingface_api_key = user_secrets.get_secret(\"huggingface-kenya-clinical-reasoning-key\")\n",
        "\n",
        "if DEV_ENV.__contains__(\"colab\"):\n",
        "    from google.colab import userdata as user_secrets\n",
        "\n",
        "    # get secret keys dd\n",
        "    #wandb_api_key = user_secrets.get(\"wandb-kenya-clinical-reasoning-key\")\n",
        "    #huggingface_api_key = user_secrets.get(\"huggingface-kenya-clinical-reasoning-key\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-OhnFYadbSH"
      },
      "source": [
        "# 2. Install and import modules\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR-XDvtsISzN",
        "outputId": "6107bfec-aaa1-4793-9220-787cd09ff8cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d06f84b4d90273dcd4dccb8121abf6e525fef332cbb6107e730ec20763eb027f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-20T20:16:36.880055Z",
          "iopub.status.busy": "2025-04-20T20:16:36.879880Z",
          "iopub.status.idle": "2025-04-20T20:19:28.326537Z",
          "shell.execute_reply": "2025-04-20T20:19:28.325572Z",
          "shell.execute_reply.started": "2025-04-20T20:16:36.880041Z"
        },
        "id": "s7kHoY_fdbSH",
        "outputId": "c6413d74-9c8e-41f6-e128-ef25c59727a3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting xformers==0.0.29.post3\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Collecting trl==0.15.2\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Collecting cut_cross_entropy\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting unsloth_zoo\n",
            "  Downloading unsloth_zoo-2025.5.8-py3-none-any.whl.metadata (8.0 kB)\n",
            "Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading unsloth_zoo-2025.5.8-py3-none-any.whl (146 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.6/146.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers, unsloth_zoo, trl, cut_cross_entropy, bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 trl-0.15.2 unsloth_zoo-2025.5.8 xformers-0.0.29.post3\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (5.29.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.2)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (0.1.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.5.7-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth-2025.5.7-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unsloth\n",
            "Successfully installed unsloth-2025.5.7\n"
          ]
        }
      ],
      "source": [
        "# Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-20T20:48:49.924662Z",
          "iopub.status.busy": "2025-04-20T20:48:49.924395Z",
          "iopub.status.idle": "2025-04-20T20:48:53.206375Z",
          "shell.execute_reply": "2025-04-20T20:48:53.204964Z",
          "shell.execute_reply.started": "2025-04-20T20:48:49.924639Z"
        },
        "id": "hhk50Bu2dbSI",
        "outputId": "4b91bb03-308e-4c45-ddaf-a63ea387158d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting weave\n",
            "  Downloading weave-0.51.47-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting diskcache==5.6.3 (from weave)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting emoji>=2.12.1 (from weave)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting gql[aiohttp,requests] (from weave)\n",
            "  Downloading gql-3.5.3-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: jsonschema>=4.23.0 in /usr/local/lib/python3.11/dist-packages (from weave) (4.23.0)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from weave) (1.6.0)\n",
            "Requirement already satisfied: numpy>1.21.0 in /usr/local/lib/python3.11/dist-packages (from weave) (2.0.2)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.11/dist-packages (from weave) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from weave) (2.11.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from weave) (13.9.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /usr/local/lib/python3.11/dist-packages (from weave) (9.1.2)\n",
            "Collecting uuid-utils>=0.9.0 (from weave)\n",
            "  Downloading uuid_utils-0.11.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: wandb>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from weave) (0.19.11)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.23.0->weave) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.23.0->weave) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.23.0->weave) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.23.0->weave) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->weave) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->weave) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->weave) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->weave) (0.4.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (8.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.17.1->weave) (75.2.0)\n",
            "Collecting graphql-core<3.2.7,>=3.2 (from gql[aiohttp,requests]->weave)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[aiohttp,requests]->weave) (1.20.0)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[aiohttp,requests]->weave)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gql[aiohttp,requests]->weave) (4.9.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from gql[aiohttp,requests]->weave) (3.11.15)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[aiohttp,requests]->weave) (1.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->weave) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->weave) (2.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (0.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.0->gql[aiohttp,requests]->weave) (1.3.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.17.1->weave) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->weave) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (5.0.2)\n",
            "Downloading weave-0.51.47-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uuid_utils-0.11.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.2/332.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gql-3.5.3-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uuid-utils, graphql-core, emoji, diskcache, backoff, gql, weave\n",
            "Successfully installed backoff-2.2.1 diskcache-5.6.3 emoji-2.14.1 gql-3.5.3 graphql-core-3.2.6 uuid-utils-0.11.0 weave-0.51.47\n"
          ]
        }
      ],
      "source": [
        "!pip install weave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T20:19:28.328868Z",
          "iopub.status.busy": "2025-04-20T20:19:28.328318Z",
          "iopub.status.idle": "2025-04-20T20:20:03.608363Z",
          "shell.execute_reply": "2025-04-20T20:20:03.607577Z",
          "shell.execute_reply.started": "2025-04-20T20:19:28.328844Z"
        },
        "id": "bsrx72UTdbSI",
        "outputId": "5ef31ecf-524a-4a78-ea4e-032179036a1f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "import glob\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Finetuning modules\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq, set_seed\n",
        "from unsloth import is_bfloat16_supported\n",
        "from datasets import load_dataset, Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T20:20:03.609295Z",
          "iopub.status.busy": "2025-04-20T20:20:03.609065Z",
          "iopub.status.idle": "2025-04-20T20:20:03.615569Z",
          "shell.execute_reply": "2025-04-20T20:20:03.614887Z",
          "shell.execute_reply.started": "2025-04-20T20:20:03.609267Z"
        },
        "id": "KOjrrLoCdbSI",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def save_versioned_config(config, config_dir='./', prefix='config_v'):\n",
        "    \"\"\"\n",
        "    Save a configuration with versioning.\n",
        "\n",
        "    Parameters:\n",
        "        config: Configuration dictionary to save\n",
        "        config_dir: Directory to save config in\n",
        "        prefix: Prefix for the config filename\n",
        "\n",
        "    Returns:\n",
        "        Path to the saved config file\n",
        "    \"\"\"\n",
        "    # Create version string with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{prefix}{timestamp}.yaml\"\n",
        "    filepath = os.path.join(config_dir, filename)\n",
        "\n",
        "    # Save the configuration\n",
        "    with open(filepath, 'w') as f:\n",
        "        yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "    print(f\"Saved configuration to: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "def load_latest_config(config_dir='./', prefix='config_v'):\n",
        "    \"\"\"\n",
        "    Find and load the most recent versioned YAML configuration file.\n",
        "\n",
        "    Args:\n",
        "        config_dir: Directory containing config files\n",
        "        prefix: Prefix of the config filenames\n",
        "\n",
        "    Returns:\n",
        "        The loaded configuration as a dictionary\n",
        "    \"\"\"\n",
        "    # Find all config files matching the pattern\n",
        "    config_files = glob.glob(f\"{config_dir}{prefix}*.yaml\")\n",
        "\n",
        "    if not config_files:\n",
        "        raise FileNotFoundError(f\"No configuration files found matching {prefix}*.yaml\")\n",
        "\n",
        "    # Sort files by modification time (newest first)\n",
        "    latest_file = max(config_files, key=os.path.getmtime)\n",
        "\n",
        "    print(f\"Loading latest configuration from: {latest_file}\")\n",
        "\n",
        "    # Load and return the configuration\n",
        "    with open(latest_file, 'r') as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "\n",
        "def load_config(path: str):\n",
        "\n",
        "    # Load and return the configuration\n",
        "    with open(path, 'r') as f:\n",
        "        return yaml.safe_load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edOOrE9QdbSJ"
      },
      "source": [
        "# 3. Setup Config\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T20:21:27.147300Z",
          "iopub.status.busy": "2025-04-20T20:21:27.146706Z",
          "iopub.status.idle": "2025-04-20T20:21:27.155011Z",
          "shell.execute_reply": "2025-04-20T20:21:27.154187Z",
          "shell.execute_reply.started": "2025-04-20T20:21:27.147247Z"
        },
        "id": "pGc-93U0dbSJ",
        "outputId": "2bd0b0e3-8592-4302-9112-16723ced9539",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved configuration to: /content/workspace/config/finetune_config_v20250522_134537.yaml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'evaluation': {'eval_steps': 50,\n",
              "  'save_steps': 50,\n",
              "  'save_total_limit': 3,\n",
              "  'strategy': 'steps'},\n",
              " 'lora': {'alpha': 32,\n",
              "  'dropout': 0.1,\n",
              "  'r': 16,\n",
              "  'target_modules': ['q_proj',\n",
              "   'k_proj',\n",
              "   'v_proj',\n",
              "   'o_proj',\n",
              "   'gate_proj',\n",
              "   'up_proj']},\n",
              " 'model': {'base_model': 'unsloth/Llama-3.2-1B-Instruct-bnb-4bit',\n",
              "  'dtype': None,\n",
              "  'load_in_4bit': True,\n",
              "  'max_seq_length': 2048},\n",
              " 'tokenizer': {'chat_template': 'llama-3.2'},\n",
              " 'training': {'batch_size': 2,\n",
              "  'epochs': 3,\n",
              "  'gradient_accumulation_steps': 1,\n",
              "  'learning_rate': 5e-05,\n",
              "  'lr_scheduler': 'cosine',\n",
              "  'optim': 'adamw_torch',\n",
              "  'output_dir': '/content/workspace/models/finetuned-model',\n",
              "  'warmup_ratio': 0.03,\n",
              "  'weight_decay': 0.01}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create dict YAML configuration\n",
        "config_dict = {\n",
        "    \"model\": {\n",
        "        \"base_model\": \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "        \"load_in_4bit\": True,\n",
        "        \"max_seq_length\": 2048,\n",
        "        \"dtype\": None\n",
        "    },\n",
        "    \"lora\": {\n",
        "        \"r\": 16,\n",
        "        \"alpha\": 32,\n",
        "        \"dropout\": 0.1,\n",
        "        \"target_modules\": [\n",
        "            \"q_proj\",\n",
        "            \"k_proj\",\n",
        "            \"v_proj\",\n",
        "            \"o_proj\",\n",
        "            \"gate_proj\",\n",
        "            \"up_proj\"\n",
        "        ]\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"batch_size\": 2,\n",
        "        \"epochs\": 3,\n",
        "        \"optim\": \"adamw_torch\",\n",
        "        \"lr_scheduler\": 'cosine',\n",
        "        \"gradient_accumulation_steps\": 1,\n",
        "        \"warmup_ratio\": 0.03,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"output_dir\": FINETUNED_MODELS_PATH\n",
        "    },\n",
        "  \"evaluation\": {\n",
        "      \"strategy\": 'steps',\n",
        "      \"eval_steps\": 50,\n",
        "      \"save_steps\": 50,\n",
        "      \"save_total_limit\": 3,\n",
        "  },\n",
        "  \"tokenizer\":{\n",
        "    \"chat_template\":\"llama-3.2\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# save as yaml config\n",
        "latest_config_version_path: str = save_versioned_config(config=config_dict,\n",
        "                                                        config_dir=CONFIG_PATH,\n",
        "                                                        prefix='finetune_config_v'\n",
        "                                                       )\n",
        "\n",
        "# load configurations\n",
        "finetune_config: dict  = load_config(path=latest_config_version_path)\n",
        "\n",
        "finetune_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdcfXrE1dbSJ"
      },
      "source": [
        "# Dataset preprocessing\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Tasks To Do:**\n",
        "1. **Load raw datasets**\n",
        " - Load train data - `os.path.join(DATASETS_PATH,\"train_dataset.csv\")`\n",
        " - Load validation data - `os.path.join(DATASETS_PATH,\"validation_dataset.csv\")`\n",
        " - Load test data - `os.path.join(DATASETS_PATH,\"test_dataset.csv\")`\n",
        "2. **Convert Pandas format to HuggingFace dataset format**\n",
        "  -  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znfNuglAQnD6"
      },
      "outputs": [],
      "source": [
        "# Template for gemma\n",
        "template = \"\"\"<bos><start_of_turn>user\n",
        "<<PROMPT>><end_of_turn>\n",
        "<start_of_turn>model\n",
        "<<CLINICIAN<end_of_turn>\"\"\"\n",
        "\n",
        "def expand_df(df, template):\n",
        "    rows = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        base = row.to_dict()\n",
        "\n",
        "        text_clinician = row['Clinician']#template.replace(\"<<CLINICIAN>>\", row['Clinician'], 1).replace(\"<<PROMPT>>\", row['Prompt'], 1)\n",
        "        base['text'] = text_clinician\n",
        "        rows.append(base.copy())\n",
        "\n",
        "        for tool_col in ['GPT4.0', 'LLAMA', 'GEMINI']:\n",
        "            tool_value = row[tool_col]\n",
        "            if pd.notna(tool_value):\n",
        "                new_row = row.to_dict()\n",
        "                text_tool = tool_value #template.replace(\"<<CLINICIAN>>\", tool_value, 1).replace(\"<<PROMPT>>\", row['Prompt'], 1)\n",
        "                new_row['text'] = text_tool\n",
        "                rows.append(new_row)\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T21:20:13.285460Z",
          "iopub.status.busy": "2025-04-20T21:20:13.284875Z",
          "iopub.status.idle": "2025-04-20T21:20:13.289902Z",
          "shell.execute_reply": "2025-04-20T21:20:13.289293Z",
          "shell.execute_reply.started": "2025-04-20T21:20:13.285436Z"
        },
        "id": "DJBkshJOdbSJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def format_data_llama_3(dataset, prompt_column_name: str, response_column_name: str, system_prompt: str=None):\n",
        "    \"\"\"Format data for Llama 3's chat template.\"\"\"\n",
        "\n",
        "    formatted_data = []\n",
        "\n",
        "    if system_prompt is None:\n",
        "       system_prompt = \"You are a clinical reasoning assistant trained to help diagnose medical conditions. Provide detailed, evidence-based assessments. Always consider patient safety first.\"\n",
        "\n",
        "    for row in dataset:\n",
        "        # Format according to Llama 3 chat template\n",
        "        formatted_text = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n{row[prompt_column_name]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n{row[response_column_name]}<|eot_id|>\"\n",
        "        formatted_data.append({\"text\": formatted_text})\n",
        "\n",
        "    return Dataset.from_list(formatted_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGg5O9SfREEX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T21:40:27.647466Z",
          "iopub.status.busy": "2025-04-20T21:40:27.647093Z",
          "iopub.status.idle": "2025-04-20T21:40:27.695600Z",
          "shell.execute_reply": "2025-04-20T21:40:27.694987Z",
          "shell.execute_reply.started": "2025-04-20T21:40:27.647445Z"
        },
        "id": "b7kdgoYfdbSK",
        "outputId": "e53b5f67-0498-442a-f14c-7e5ef811469d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train_raw\",\n  \"rows\": 344,\n  \"fields\": [\n    {\n      \"column\": \"Master_Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"ID_GRATU\",\n          \"ID_VBULH\",\n          \"ID_WQTSF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"i am a nurse with 17 years of experience in general nursing working in a dispensaries and private clinics in kakamega county in kenya a client age 24 years a male came in unconscious accompanied with a cook he was a kmtc student who had a history of having only one meal per day rbs done sugars were 2 mrdt was negative and vital signs were normal what can i do to raise sugars can i do guiding and counselling on feeding practices\",\n          \"i am a nurse with 1 years of experience in general nursing working in a sub county hospitals and nursing homes in uasin gishu county in kenya a 65 year old male is brought to the facility with complains of worsening shortness of breath fatigue and lower extremity edema for the past 3 days he has history of chronic heart failure with non compliance to medications and dietary restrictions on assessment bp 160 90mmhg hr 112b min resp 25b min spo2 82 lung auscultation crackles heard questions what is the immediate management what is the pathophysiology of chronic heart failure what is the health education for the patient on drug compliance\",\n          \"i am a nurse with 24 years of experience in general nursing working in a health centres in uasin gishu county in kenya a 27 year old male is brought to the clinic complaining of constipation he says he took a mixture of maize and beans \\u2013 \\u2018githeri\\u2019 \\u2013 for lunch he is a casual laborer in a construction company vital signs temp 360 c pulse \\u2013 90 resp \\u2013 28 questions what is the diagnosis what is the treatment what investigations are necessary for him\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clinician\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"summary a 24 year old male presented unconscious history of having only 1 meal rbs done 2 mmol l normal vitals mrdt is negative management 1 oral glucose if the patient is conscious you can dissolve sugar or give any sugary drink to the patient 2 intravenous dextrose administer 10 or 5 dextrose via an iv access 3 consider counselling on feeding practices regular meals balance diets recognition of early warning signs diagnosis hypoglycemia\",\n          \"summary 65 year old male with history of chronic heart failure with non compliance presents with dyspnea fatigue and lower limb edema he is hypertensive tachycardic tachypneic saturating at 92 with crackles on auscultation diagnosis acute exacerbation of heart failure management prop up patient monitor input output start the patient on diuretics to manage fluid overload start guideline directed medical therapy for management of heart failure with a reduced ejection fraction manage hypertension with antihypertensives advise the patient on compliance\",\n          \"summary a 27 year old male brought to uasin gishu clinic presenting with constipation he took githeri for lunch he is a casual labourer in a construction company vitals temperature 36oc pulse rate 90 respiratory rate 28 breath per minute what is the diagnosis food poisoning respiratory rate of 28 breath per minute may be due to sepsis constipation secondary to food diet lacking fibers vegetables water what investigations are necessary for him full haemogram to assess white blood cell status abdominal ultrasound to assess bowel movements erect abdominal x ray to rule out gas levels stool for widal slide agglutination test and helicobacter pylori stool test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train_raw"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b0dcc3fc-6dcf-4a5f-be83-37d3fcaf683d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Master_Index</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Clinician</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_XMBBY</td>\n",
              "      <td>i am a nurse with 17 years of experience in ge...</td>\n",
              "      <td>summary 6 year old present with vomiting and a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0dcc3fc-6dcf-4a5f-be83-37d3fcaf683d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0dcc3fc-6dcf-4a5f-be83-37d3fcaf683d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0dcc3fc-6dcf-4a5f-be83-37d3fcaf683d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e3078aab-503c-46a1-b010-61347a8c8b51\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3078aab-503c-46a1-b010-61347a8c8b51')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e3078aab-503c-46a1-b010-61347a8c8b51 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  Master_Index                                             Prompt  \\\n",
              "0     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "1     ID_XMBBY  i am a nurse with 17 years of experience in ge...   \n",
              "\n",
              "                                           Clinician  \n",
              "0  summary a 4 year old with 5 superficial burns ...  \n",
              "1  summary 6 year old present with vomiting and a...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load training dataset with selected columns\n",
        "df_train_raw = pd.read_csv(os.path.join(DATASETS_PATH,\"train_dataset.csv\"),\n",
        "                           usecols=['Master_Index', 'Prompt','Clinician' ]\n",
        "                          )\n",
        "\n",
        "df_validation_raw = pd.read_csv(os.path.join(DATASETS_PATH,\"validation_dataset.csv\"),\n",
        "                           usecols=['Master_Index', 'Prompt','Clinician' ]\n",
        "                          )\n",
        "\n",
        "df_test_raw = pd.read_csv(os.path.join(DATASETS_PATH,\"test_dataset.csv\"),\n",
        "                           usecols=['Master_Index', 'Prompt']\n",
        "                          )\n",
        "\n",
        "df_online_test_raw = pd.read_csv(os.path.join(DATASETS_PATH,\"online_test.csv\"),\n",
        "                           usecols=['Master_Index', 'Prompt']\n",
        "                          )\n",
        "\n",
        "\n",
        "df_train_raw.head(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "fRIvl7XSUxII",
        "outputId": "811bcfd8-1428-46f1-d1d4-a74324f0aa96"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train_formatted\",\n  \"rows\": 1376,\n  \"fields\": [\n    {\n      \"column\": \"Master_Index\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"ID_GRATU\",\n          \"ID_VBULH\",\n          \"ID_WQTSF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"i am a nurse with 17 years of experience in general nursing working in a dispensaries and private clinics in kakamega county in kenya a client age 24 years a male came in unconscious accompanied with a cook he was a kmtc student who had a history of having only one meal per day rbs done sugars were 2 mrdt was negative and vital signs were normal what can i do to raise sugars can i do guiding and counselling on feeding practices\",\n          \"i am a nurse with 1 years of experience in general nursing working in a sub county hospitals and nursing homes in uasin gishu county in kenya a 65 year old male is brought to the facility with complains of worsening shortness of breath fatigue and lower extremity edema for the past 3 days he has history of chronic heart failure with non compliance to medications and dietary restrictions on assessment bp 160 90mmhg hr 112b min resp 25b min spo2 82 lung auscultation crackles heard questions what is the immediate management what is the pathophysiology of chronic heart failure what is the health education for the patient on drug compliance\",\n          \"i am a nurse with 24 years of experience in general nursing working in a health centres in uasin gishu county in kenya a 27 year old male is brought to the clinic complaining of constipation he says he took a mixture of maize and beans \\u2013 \\u2018githeri\\u2019 \\u2013 for lunch he is a casual laborer in a construction company vital signs temp 360 c pulse \\u2013 90 resp \\u2013 28 questions what is the diagnosis what is the treatment what investigations are necessary for him\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clinician\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"summary a 24 year old male presented unconscious history of having only 1 meal rbs done 2 mmol l normal vitals mrdt is negative management 1 oral glucose if the patient is conscious you can dissolve sugar or give any sugary drink to the patient 2 intravenous dextrose administer 10 or 5 dextrose via an iv access 3 consider counselling on feeding practices regular meals balance diets recognition of early warning signs diagnosis hypoglycemia\",\n          \"summary 65 year old male with history of chronic heart failure with non compliance presents with dyspnea fatigue and lower limb edema he is hypertensive tachycardic tachypneic saturating at 92 with crackles on auscultation diagnosis acute exacerbation of heart failure management prop up patient monitor input output start the patient on diuretics to manage fluid overload start guideline directed medical therapy for management of heart failure with a reduced ejection fraction manage hypertension with antihypertensives advise the patient on compliance\",\n          \"summary a 27 year old male brought to uasin gishu clinic presenting with constipation he took githeri for lunch he is a casual labourer in a construction company vitals temperature 36oc pulse rate 90 respiratory rate 28 breath per minute what is the diagnosis food poisoning respiratory rate of 28 breath per minute may be due to sepsis constipation secondary to food diet lacking fibers vegetables water what investigations are necessary for him full haemogram to assess white blood cell status abdominal ultrasound to assess bowel movements erect abdominal x ray to rule out gas levels stool for widal slide agglutination test and helicobacter pylori stool test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPT4.0\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"given the scenario you ve described the first priority is to raise the client s blood sugar to stabilize his condition especially since his rbs random blood sugar was 2 which is very low and could be indicative of hypoglycemia immediate action 1 administer glucose o oral glucose if the patient regains consciousness you can give oral glucose glucose tablets honey or a sugary drink to quickly raise blood sugar levels o intravenous iv glucose if the patient remains unconscious or unable to swallow you should administer 25 50 ml of 50 dextrose d50 via iv or if unavailable 10 dextrose can be used this should be done carefully and monitored 2 monitor blood glucose levels after administering glucose continue to monitor the patient s blood glucose closely to ensure it normalizes 3 hydration ensure the patient is well hydrated as dehydration can exacerbate hypoglycemia iv fluids such as normal saline or ringer s lactate may be used if necessary guiding and counseling on feeding practices \\u2022 educating the client once the patient is conscious and stable counseling on proper feeding practices is crucial particularly given his history of consuming only one meal a day which can contribute to blood sugar fluctuations you could discuss o the importance of eating regular meals ideally 3 5 balanced meals per day to maintain stable blood glucose levels o the need for a balanced diet with a mix of carbohydrates proteins and healthy fats to prevent sudden drops in blood sugar o avoiding long periods of fasting without eating especially if engaging in strenuous activities or studying o the inclusion of snacks between meals especially if they have a busy lifestyle or long study hours to prevent hypoglycemia o educating him about recognizing signs of low blood sugar such as dizziness sweating confusion and how to respond next steps \\u2022 follow up you may want to recommend a follow up visit to ensure he is adjusting his diet and lifestyle to prevent recurrence \\u2022 referral if necessary refer the client to a nutritionist or dietitian for further advice on managing a balanced diet would you like more specific guidance on any of these areas\",\n          \"immediate management for a 65 year old male with worsening shortness of breath fatigue lower extremity edema and a history of chronic heart failure chf who presents with elevated blood pressure tachycardia tachypnea and hypoxia the following immediate management steps are critical 1 oxygen therapy o administer oxygen to maintain oxygen saturation above 92 this will help improve his hypoxia spo2 82 and reduce the strain on his heart 2 monitor vital signs o continuous monitoring of vital signs blood pressure heart rate respiratory rate and oxygen saturation is essential to assess the response to treatment and detect any deterioration 3 positioning o place the patient in a high fowler\\u2019s position sitting up at a 45 60 degree angle to reduce the workload on the heart and improve breathing by allowing better lung expansion 4 diuretic therapy o administer intravenous diuretics e g furosemide to reduce fluid overload which is contributing to edema and the patient s shortness of breath dyspnea diuretics will help relieve pulmonary congestion and decrease peripheral edema 5 vasodilators o nitroglycerin or other vasodilators may be considered if there is evidence of significant preload and afterload increase hypertension and signs of fluid overload these medications will help reduce the heart s workload by dilating blood vessels 6 cardiac monitoring o continuous cardiac monitoring is necessary due to the tachycardia hr 112 and the risk of arrhythmias in patients with chf 7 iv access o establish an iv line for medication administration fluid management and to ensure that diuretics and vasodilators can be given promptly 8 electrolyte monitoring o monitor electrolytes especially potassium and sodium as they may be affected by diuretics and heart failure treatment 9 close monitoring for signs of acute decompensated heart failure adhf o assess for worsening signs of fluid overload including increasing shortness of breath orthopnea or worsening edema 10 consideration for non invasive ventilation niv o if the patient is severely hypoxic spo2 90 consider non invasive ventilation niv e g bipap or cpap to help reduce respiratory distress and improve oxygenation especially if they are in acute pulmonary edema pathophysiology of chronic heart failure chronic heart failure chf is a complex condition where the heart is unable to pump blood effectively to meet the body s needs the pathophysiology involves several key mechanisms 1 impaired cardiac output o the heart s inability to pump blood efficiently results in reduced cardiac output this causes inadequate perfusion of organs and tissues leading to symptoms such as fatigue weakness and shortness of breath 2 neurohormonal activation o in response to reduced cardiac output the body activates compensatory mechanisms such as sympathetic nervous system activation increased heart rate and contractility renin angiotensin aldosterone system raas activation leading to sodium and water retention increased blood volume and vasoconstriction antidiuretic hormone adh release contributing to fluid retention and worsening edema 3 pulmonary congestion o the left ventricle is often impaired in chf leading to a backlog of blood in the pulmonary circulation causing pulmonary edema resulting in symptoms such as shortness of breath crackles on auscultation and reduced oxygen saturation 4 systemic congestion o the right ventricle may also become affected leading to systemic venous congestion which causes peripheral edema ascites and hepatomegaly enlarged liver 5 ventricular remodeling o over time the heart undergoes structural changes remodeling including dilation of the chambers thickening of the heart walls and fibrosis which further impairs the heart\\u2019s ability to pump effectively 6 decreased tissue perfusion o chronic underperfusion of organs can lead to worsening symptoms such as fatigue confusion and weakness due to inadequate oxygen and nutrient delivery health education on drug compliance patient education is a crucial component in managing chronic heart failure and ensuring the patient adheres to their treatment plan key points for educating the patient on drug compliance include 1 importance of medication adherence o explain that medications such as diuretics ace inhibitors beta blockers and angiotensin receptor blockers arbs help manage symptoms improve heart function and reduce hospitalizations non compliance can lead to worsened symptoms increased fluid retention and frequent hospital visits 2 understanding the role of diuretics o emphasize that diuretics help control fluid buildup reduce swelling edema and alleviate shortness of breath patients should understand the importance of taking diuretics as prescribed to avoid worsening fluid retention 3 dietary and lifestyle modifications o discuss the importance of a low salt diet to help manage fluid retention o encourage regular exercise as tolerated and weight monitoring to detect early signs of fluid buildup weight gain 4 recognizing signs of fluid retention o educate the patient to monitor for worsening edema weight gain or increased shortness of breath these symptoms should prompt the patient to seek medical attention immediately 5 managing hypertension o explain that blood pressure control is critical in managing heart failure medications prescribed for high blood pressure like ace inhibitors and beta blockers are essential for preventing further heart damage and reducing the risk of heart failure exacerbation 6 consequence of missing doses o stress that missing medication doses can lead to a worsening of heart failure resulting in hospital readmission difficulty breathing and other serious complications 7 follow up care o stress the importance of regular follow up visits with the healthcare provider to monitor the progress of the condition adjust medications and assess for any complications if any side effects or concerns arise they should contact the healthcare team immediately 8 emergency plan o instruct the patient and family to seek immediate medical help if the patient experiences severe shortness of breath swelling or other worsening symptoms that may indicate decompensation summary the immediate management of this patient with worsening heart failure includes oxygen therapy diuretic administration and hemodynamic support the pathophysiology of chronic heart failure involves impaired cardiac output neurohormonal activation and fluid retention leading to pulmonary and systemic congestion health education should focus on the importance of drug compliance managing salt intake recognizing early signs of fluid retention and maintaining regular follow ups\",\n          \"patient profile \\u2022 age 27 year old male \\u2022 presenting complaint constipation following a meal of maize and beans githeri \\u2022 occupation casual laborer in a construction company \\u2022 vital signs o temperature 36 0\\u00b0c normal o pulse 90 beats per minute slightly elevated but within acceptable range o respiratory rate 28 breaths per minute slightly elevated indicating possible discomfort or distress differential diagnosis the patient presents with constipation after consuming a meal of maize and beans there are a few potential causes for his symptoms 1 simple constipation o the most likely diagnosis is simple constipation this can occur after a meal high in fiber such as maize and beans which are rich in carbohydrates and fiber for some individuals a sudden or large amount of fiber intake can cause temporary constipation if their gut is not used to such a diet o maize and beans githeri are known for being difficult to digest for some people especially if they are not adequately prepared e g if beans were not properly soaked or cooked this can lead to bloating delayed digestion and constipation 2 gastrointestinal gi disturbance or irritable bowel syndrome ibs o irritable bowel syndrome ibs could be another possibility especially if the patient has had a history of intermittent abdominal discomfort bloating and altered bowel habits ibs is often triggered by dietary changes or stress both of which could be factors for this patient especially considering his manual labor job and possible dietary changes 3 dehydration o as a construction worker the patient may be exposed to hot and physical working conditions which could result in dehydration dehydration is a common cause of constipation because it leads to more water being absorbed from the stool in the colon resulting in hard dry stools that are difficult to pass 4 food intolerance or sensitivity o the patient could have a mild food intolerance to beans or maize foods high in fiber or complex carbohydrates can sometimes cause discomfort in people with sensitivities leading to constipation bloating or gas in this case the discomfort might be exacerbated by the amount of beans consumed in the meal 5 infectious gastroenteritis o while the patient\\u2019s symptoms primarily suggest constipation a gastrointestinal infection could also be considered if there is a suspicion that the maize and beans were contaminated however infections typically present with other symptoms such as diarrhea vomiting fever or abdominal pain given the normal temperature this seems less likely 6 abdominal obstruction o though less likely in this case a bowel obstruction should be considered if the constipation is severe persistent or accompanied by severe abdominal pain vomiting or inability to pass gas this could be due to a variety of causes such as a mechanical blockage or previous abdominal surgeries this should be considered if his symptoms worsen or are associated with other signs of obstruction treatment 1 dietary adjustments o increase fluid intake encourage the patient to drink plenty of fluids water oral rehydration solutions to help soften the stool and prevent dehydration o gradual increase in fiber if the patient\\u2019s diet is too low in fiber it\\u2019s essential to increase fiber intake gradually to allow the intestines to adapt given that beans and maize are high in fiber recommend a more balanced diet with a variety of fiber sources e g fruits vegetables whole grains 2 laxatives o if the constipation is significant a mild laxative can be prescribed to help relieve the discomfort options include bulk forming laxatives e g psyllium husk these help to add bulk to stool and improve motility stool softeners e g docusate sodium these can help soften hard stools making them easier to pass osmotic laxatives e g polyethylene glycol these draw water into the colon to soften stool and promote bowel movement 3 abdominal massage and positioning o gentle abdominal massage may help promote bowel motility and relieve discomfort o encourage the patient to engage in regular physical activity to improve bowel function e g walking light exercise 4 relieve abdominal discomfort o if the patient is experiencing bloating or gas a simethicone product an anti gas medication can be useful to relieve the discomfort investigations 1 physical examination o abdominal examination carefully assess the abdomen for signs of bloating tenderness or distension palpate for any abnormal masses or signs of obstruction o rectal examination if necessary a rectal examination can be performed to assess for impacted stool or signs of hemorrhoids 2 stool analysis o if there is any suspicion of infection especially if the patient develops diarrhea fever or vomiting a stool sample should be sent for analysis to check for pathogens like bacteria parasites or ova given the absence of fever in this case an infection seems less likely at the moment but it may still be worth considering in case symptoms worsen 3 electrolyte and renal function tests o if the patient is dehydrated especially considering his work environment assess electrolyte levels and renal function e g serum sodium potassium creatinine to evaluate for dehydration related issues 4 thyroid function tests if long term constipation persists o if constipation persists beyond the acute episode or if the patient has other symptoms fatigue weight changes consider checking thyroid function tsh free t3 free t4 to rule out hypothyroidism which is another common cause of constipation 5 abdominal x ray if suspicion of obstruction o if the patient develops more severe symptoms or signs of obstruction such as severe pain vomiting or inability to pass gas an abdominal x ray may be needed to rule out bowel obstruction 6 complete blood count cbc o if there is concern about a systemic infection even though unlikely a cbc could be performed to look for signs of infection or inflammation conclusion \\u2022 possible diagnosis likely simple constipation possibly aggravated by high fiber intake githeri dehydration or mild food intolerance \\u2022 immediate treatment encourage fluid intake increase fiber gradually prescribe a mild laxative or stool softener if necessary and advise the patient to engage in physical activity \\u2022 investigations physical exam stool analysis if infection suspected electrolyte tests for dehydration thyroid function tests if constipation persists and abdominal x ray if obstruction is suspected the patient should be reassured and advised to monitor his symptoms if there is no improvement or if symptoms worsen e g severe pain vomiting inability to pass stool or gas further investigations should be done to rule out more serious conditions like obstruction or infection\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LLAMA\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"first let s prioritize the patient s immediate needs with a blood sugar level of 2 your patient is in a hypoglycemic crisis this is a medical emergency that requires prompt attention to raise the patient s blood sugar level i recommend the following 1 administer oral glucose offer the patient a sugary drink like fruit juice soda or a glucose containing beverage like lucozade if the patient is unconscious you can try to give a glucose gel or a rapid acting carbohydrate like honey or sugar water 1 2 teaspoons sublingually 2 provide a snack or meal if the patient is conscious offer a snack or meal that includes a rapid acting carbohydrate and a protein source such as a banana with peanuts a handful of nuts and dried fruits or a energy bar once the patient s blood sugar level has stabilized you can focus on guiding and counseling on feeding practices it s essential to educate the patient on the importance of regular balanced meals to prevent future hypoglycemic episodes as a nurse you can 1 assess the patient s dietary habits ask the patient about their usual food intake including the frequency quantity and quality of meals identify any misconceptions or barriers to healthy eating 2 provide nutrition education counsel the patient on the importance of consuming three main meals and one or two snacks in between with a focus on balanced diets that include complex carbohydrates proteins and healthy fats 3 emphasize the need for breakfast since the patient was only having one meal per day it s crucial to stress the importance of starting the day with a nutritious breakfast to prevent hypoglycemia 4 encourage healthy snacking suggest healthy snack options like fruits nuts and energy bars to help maintain stable blood sugar levels throughout the day 5 refer to a nutritionist or a dietician if possible consider referring the patient to a nutritionist or a dietician for personalized dietary advice and guidance remember to also educate the patient on the signs and symptoms of hypoglycemia such as shakiness dizziness sweating and confusion and encourage them to seek medical attention if they experience any of these symptoms lastly consider involving the cook who accompanied the patient in the education process as they may be able to provide support and encouragement in implementing healthy dietary habits please keep me updated on the patient s progress and don t hesitate to reach out if you have any further questions or concerns\",\n          \"i ll do my best to provide guidance on the management of this patient with chronic heart failure immediate management given the patient s symptoms and physical examination findings it is likely that he has acute decompensated heart failure adhf the immediate management should focus on stabilizing the patient and relieving symptoms 1 oxygen therapy administer oxygen to relieve hypoxia and improve oxygen saturation aim for an spo2 of at least 90 2 diuretic therapy administer a loop diuretic like furosemide 40 80 mg iv to reduce fluid overload and relieve congestion monitor the patient s urine output and adjust the dose as needed 3 vasodilator therapy consider administering a vasodilator like nitroglycerin 10 20 mcg min iv to reduce preload and afterload 4 ace inhibitor or arb if the patient is not already taking an ace inhibitor or arb consider initiating or restarting this medication to reduce afterload and improve cardiac function 5 monitor vital signs closely monitor the patient s vital signs including blood pressure heart rate respiratory rate and oxygen saturation 6 electrolyte monitoring monitor electrolyte levels particularly potassium to avoid hypokalemia or hyperkalemia pathophysiology of chronic heart failure chronic heart failure chf is a complex syndrome characterized by the heart s inability to pump sufficient blood to meet the body s metabolic demands the pathophysiology involves a combination of factors including 1 cardiac remodeling the heart undergoes structural changes leading to ventricular hypertrophy fibrosis and dilation 2 neurohormonal activation the body s neurohormonal systems such as the renin angiotensin aldosterone system are activated leading to vasoconstriction sodium retention and water retention 3 decreased cardiac contractility the heart s ability to contract and pump blood is impaired leading to decreased cardiac output 4 increased peripheral resistance vasoconstriction increases peripheral resistance making it harder for the heart to pump blood health education on drug compliance it is essential to educate the patient on the importance of medication adherence to manage chronic heart failure effectively emphasize the following points 1 take medications as prescribed stress the importance of taking medications exactly as prescribed without missing doses or stopping abruptly 2 dietary restrictions reinforce the need to follow a low sodium diet restrict fluid intake and avoid foods high in salt sugar and fat 3 monitoring and follow up emphasize the importance of regular follow up appointments and monitoring vital signs to detect any changes in the patient s condition 4 lifestyle modifications encourage the patient to adopt a healthy lifestyle including regular exercise stress reduction and smoking cessation if applicable 5 medication side effects inform the patient about potential side effects of medications and what to do if they occur remember to use simple clear language and provide written instructions to reinforce the patient s understanding of their treatment plan i hope this helps let me know if you have any further questions or concerns\",\n          \"based on the information provided i ll do my best to guide you diagnosis given the patient s symptoms of constipation especially after consuming a heavy meal like githeri i would suspect that he might be experiencing a case of food poisoning or gastrointestinal upset however considering the vital signs particularly the respiratory rate of 28 which is higher than normal i wouldn t rule out the possibility of a more severe condition treatment for now let s focus on symptomatic management i would recommend the following 1 fluid replacement offer the patient plenty of oral fluids such as water or electrolyte rich drinks like coconut water or oral rehydration solution ors to prevent dehydration 2 anti emetics if the patient is experiencing nausea or vomiting consider administering an anti emetic like metoclopramide 10mg orally or intravenously 3 pain management if the patient is experiencing abdominal pain you can offer a mild analgesic like paracetamol 1g orally investigations to further assess the patient s condition and rule out other potential causes i would recommend the following investigations 1 complete blood count cbc to check for signs of infection or inflammation 2 blood glucose level to rule out hyperglycemia or hypoglycemia which could be contributing to the patient s symptoms 3 urinalysis to assess for urinary tract infections or other underlying conditions 4 stool examination to check for signs of infection such as bacterial or parasitic infections however considering the patient s vital signs especially the high respiratory rate i would also like to rule out other potential conditions like pneumonia or sepsis therefore i would recommend 1 chest x ray to assess for any signs of lung infection or inflammation 2 blood cultures to rule out sepsis or bloodstream infections referral if the patient s condition worsens or if you suspect a more severe condition consider referring him to a higher level facility for further management remember to always follow the kenya ministry of health s guidelines and protocols for managing patients with similar symptoms please let me know if you have any further questions or concerns\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GEMINI\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"this situation requires careful consideration while the low blood sugar rbs of 2 \\u2013 assuming this is mmol l which is common in kenya but needs clarification if it s mg dl it s critically low is a serious concern the unconscious state warrants a more urgent and cautious approach than simply giving sugar the fact that his other vitals are normal is slightly reassuring but it doesn t rule out other causes for his unconsciousness immediate actions 1 activate emergency response given his unconscious state this is the priority do not attempt extensive treatment without first ensuring appropriate emergency response is initiated this may involve calling an ambulance contacting a doctor or notifying your supervisor depending on your clinic s protocols 2 assess airway breathing and circulation abcs check for airway obstruction breathing difficulties and pulse if his breathing is inadequate or he s pulseless begin cpr immediately 3 administer glucose carefully while low blood sugar is likely a significant contributor do not rush to give him oral glucose if he is unconscious giving oral glucose to an unconscious person poses a choking risk if you have intravenous iv access and the appropriate training only then administer a concentrated dextrose solution under the direction of a doctor or following established protocols if iv access is not immediately available or you lack the training focus on abcs and wait for emergency medical services 4 monitor vital signs continuously closely monitor his breathing pulse blood pressure and level of consciousness until medical help arrives once stabilized and with medical supervision 5 investigate underlying causes low blood sugar can result from various conditions including diabetes although unlikely given the normal vital signs further investigations might be necessary to rule this out completely hypoglycemia from other causes pancreatic tumors medication side effects alcohol use liver disease or other metabolic disorders a detailed medical history is crucial if and when he regains consciousness malnutrition his history of eating only one meal a day is a significant risk factor for malnutrition and various complications 6 obtain further history if and when possible once he is conscious thoroughly document his history including medications alcohol or drug use any recent illnesses or injuries and a detailed dietary intake the cook may also be a valuable source of information 7 guiding and counseling after medical clearance once he is stable and conscious and under medical supervision you can begin nutritional counseling this should involve teaching him about balanced nutrition meal planning and the importance of regular meals to avoid future hypoglycemic episodes this is absolutely crucial to prevent this from happening again however this should not be done until his immediate medical needs are addressed important considerations rbs value units clarify whether the rbs of 2 is mmol l or mg dl the interpretation and urgency vary dramatically between these units training and protocols always adhere to your clinic s established protocols for managing unconscious patients and administering glucose legal and ethical implications document everything meticulously your actions should always align with professional standards and legal requirements in short focus on immediate life saving measures first do not attempt to treat his low blood sugar without appropriate medical supervision and consideration for his unconscious state addressing the underlying cause is crucial and nutritional counseling is an important aspect of his long term care but only after his immediate medical needs have been addressed and he s medically stable\",\n          \"this 65 year old male presents with a likely exacerbation of his chronic heart failure chf his symptoms shortness of breath fatigue lower extremity edema vital signs high blood pressure elevated heart rate rapid respiratory rate low spo2 and lung findings crackles all point to this immediate management the immediate priorities are to improve oxygenation and reduce the patient s cardiac workload this requires a rapid systematic approach 1 oxygen therapy administer supplemental oxygen via nasal cannula or mask to achieve spo2 90 continuously monitor spo2 2 high fowler s position elevate the patient to a semi sitting position high fowler s to facilitate breathing 3 iv access establish intravenous access for fluid administration and medication delivery 4 fluid assessment and management assess for signs of fluid overload e g jugular venous distention peripheral edema consider administering intravenous diuretics e g furosemide as ordered by a physician to reduce fluid overload monitor urine output closely 5 cardiac monitoring place the patient on continuous cardiac monitoring to assess heart rhythm and rate 6 medication administration administer medications as ordered by the physician this may include loop diuretics e g furosemide to reduce fluid volume nitrates e g nitroglycerin to reduce preload and afterload morphine in some cases cautiously to reduce anxiety and decrease preload and afterload oxygen as previously stated 7 further assessment a thorough physical exam including cardiac assessment heart sounds murmurs and neurological assessment is needed further investigations such as chest x ray ecg and blood tests including electrolytes bnp nt probnp should be ordered by a physician to aid diagnosis and guide further management 8 monitor for deterioration closely monitor vital signs respiratory status and fluid balance for any sign of worsening condition requiring escalation of care pathophysiology of chronic heart failure chronic heart failure is a clinical syndrome where the heart is unable to pump enough blood to meet the body s metabolic demands this can result from various underlying causes including reduced cardiac output the heart s ability to contract and pump blood is impaired leading to decreased blood flow to tissues this can be due to systolic dysfunction impaired ability of the heart muscle to contract effectively reduced ejection fraction diastolic dysfunction impaired ability of the heart muscle to relax and fill properly neurohormonal activation the body attempts to compensate for reduced cardiac output by activating the sympathetic nervous system and the renin angiotensin aldosterone system raas this leads to increased heart rate blood pressure and fluid retention further stressing the heart myocardial remodeling over time the heart muscle undergoes structural changes hypertrophy fibrosis making it less efficient fluid retention reduced cardiac output triggers the kidneys to retain sodium and water in an attempt to increase blood volume and pressure this leads to edema particularly in the lower extremities and lungs health education for patient on drug compliance non compliance is a major obstacle in chf management education needs to be clear simple and tailored to the patient s understanding key points include importance of medication explain clearly why each medication is necessary and how it helps manage the heart condition use visual aids if helpful medication schedule provide a clear written schedule for taking medications and emphasize the importance of adhering to it consider using pill organizers dietary restrictions explain the importance of a low sodium diet to reduce fluid retention provide specific examples of foods to avoid and alternatives limit alcohol and caffeine intake weight monitoring instruct the patient to monitor their weight daily and report any significant weight gain e g 2 pounds in a day or 5 pounds in a week immediately to their healthcare provider as this can indicate fluid retention symptom recognition teach the patient to recognize the early warning signs of chf exacerbation e g increasing shortness of breath swelling in ankles legs sudden weight gain fatigue and to seek medical attention promptly lifestyle modifications encourage regular exercise as tolerated stress reduction techniques and smoking cessation follow up appointments emphasize the importance of regular follow up appointments for monitoring and adjustments to medication support system encourage patient to involve family members in their care and medication management for better compliance also exploring support groups can help with compliance important note as a nurse your role is to implement the physician s orders and provide patient care you should not prescribe medications or make independent treatment decisions always follow established protocols and seek guidance from your supervising physician or other senior medical staff as needed\",\n          \"based on the limited information provided it s impossible to give a definitive diagnosis constipation is a symptom not a disease and many things can cause it however we can discuss possibilities investigations and treatment possible diagnoses differential diagnoses simple constipation this is the most likely diagnosis given the history the githeri while a healthy food can be constipating for some individuals particularly if lacking sufficient fiber or fluids his activity level as a casual laborer might also play a role obstruction less likely while less probable given the lack of other significant symptoms an intestinal obstruction needs to be considered this would present with more severe symptoms such as significant abdominal pain vomiting and possibly distension other causes less likely possibilities include medication side effects though not mentioned irritable bowel syndrome ibs or other underlying gastrointestinal disorders investigations necessary given the limited symptoms initial investigations should be focused on ruling out more serious causes 1 abdominal examination a thorough physical exam focusing on the abdomen is crucial look for tenderness distension masses or other abnormalities auscultation listening to bowel sounds can help assess intestinal motility 2 rectal examination this can check for stool impaction which is a common cause of constipation especially in older individuals however given the patient s age and history it is less likely but still important to rule out 3 full blood count fbc this could be useful in identifying any underlying infection or inflammatory condition that might be contributing to the constipation 4 further investigations if indicated if the abdominal examination reveals abnormalities or if the patient\\u2019s condition doesn\\u2019t improve with initial treatment further investigations such as an abdominal x ray or ultrasound might be necessary to rule out an obstruction treatment the treatment plan depends on the underlying cause which is why thorough assessment and possibly some investigations are vital however given the likely diagnosis of simple constipation initial treatment would focus on 1 increased fluid intake encourage increased water intake at least 2 liters per day 2 dietary changes advise increasing fiber intake through fruits vegetables and whole grains however introduce high fiber foods gradually to avoid gas and bloating 3 laxatives if necessary if the constipation doesn t resolve with increased fluids and dietary changes a mild osmotic laxative such as polyethylene glycol or lactulose or a stool softener may be considered bulk forming laxatives are also an option but need sufficient fluid intake this should be done with caution and under medical supervision especially considering the patient\\u2019s age and apparent good health 4 regular exercise encourage regular physical activity to help stimulate bowel movements important considerations patient education educate the patient about the importance of adequate hydration and fiber in their diet for preventing future constipation follow up schedule a follow up appointment to assess the effectiveness of treatment and address any ongoing concerns red flags if the patient develops severe abdominal pain vomiting fever or inability to pass gas seek immediate medical attention as this could indicate a serious condition disclaimer this information is for educational purposes only and should not be considered medical advice always consult with a physician or other qualified healthcare professional for any health concerns or before making any decisions related to your health or treatment the information provided here is based solely on the limited data in your question and shouldn\\u2019t replace a proper medical evaluation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1376,\n        \"samples\": [\n          \"this situation requires immediate and careful action the priority for the 7 year old girl is her immediate physical and psychological well being this is a serious case that falls under gender based violence gbv priority treatment 1 stabilize the patient address the immediate physical needs this includes stop the bleeding clean the vaginal area gently and apply appropriate dressings to control bleeding do not insert anything into the vagina pain management administer analgesics as needed appropriate for her age and weight assess for other injuries a thorough physical examination is crucial to identify any other injuries including internal injuries this may require referral to a hospital with better facilities iv fluids if she is showing signs of dehydration or shock administer iv fluids prophylactic antibiotics consider prophylactic antibiotics to prevent infection given the lacerations and bleeding this should be guided by local guidelines and antibiotic sensitivity patterns sti testing and prophylaxis obtain samples for sexually transmitted infection sti testing including hiv syphilis etc and provide appropriate prophylaxis this needs to be done according to local protocols 2 referral immediately refer the girl to a hospital with specialized pediatric care and capacity for managing sexual assault cases she will likely need forensic examination a comprehensive forensic examination is crucial to collect evidence for potential legal proceedings this examination should be conducted by a trained professional specialized medical care this may include surgery to repair lacerations if necessary psychological support a child psychologist or psychiatrist is essential to provide trauma informed care and support 3 ongoing monitoring closely monitor her condition for any complications like infection or psychological distress gbv classification yes this unequivocally falls under gender based violence gbv the sexual assault of a child is a severe form of gbv and it s crucial to treat it as such p3 forms in kenya a p3 form is a medical report used in legal processes related to assault yes you should document this case meticulously in a p3 form accurate documentation is critical for legal proceedings and to ensure justice for the child make sure you document the nature of the injuries the circumstances surrounding the assault as reported by the uncle the girl\\u2019s statement if she is able to provide one remember to be sensitive and avoid leading questions any other relevant information important considerations child protection the safety and well being of the child are paramount you should work with child protection services to ensure she is placed in a safe environment consider reporting to the relevant authorities immediately confidentiality maintain strict confidentiality throughout the process support for the uncle while the focus must be on the child offering the uncle support might lead to him being more cooperative collaboration work closely with other healthcare professionals law enforcement and child protection agencies to ensure the child receives the best possible care and justice this situation requires immediate action act swiftly and decisively prioritizing the child\\u2019s physical and psychological well being while ensuring the appropriate legal and investigative steps are taken do not hesitate to seek assistance from your supervisors and other professionals with expertise in gbv and child sexual assault\",\n          \"this case presents a concerning situation a one month old infant with a persistently wet and pulsating umbilical cord stump this strongly suggests a failure of umbilical cord separation and potentially a serious underlying condition possible risks involved infection omphalitis this is the most immediate and significant risk a wet pulsating cord is a breeding ground for bacteria infection can spread locally causing cellulitis and abscess formation or systemically leading to sepsis a life threatening bloodstream infection the presence of a pulse indicates potential vascular involvement increasing the severity of infection risk umbilical granuloma while less serious than omphalitis a granuloma is a persistent inflamed nodule at the umbilical site it can be a source of bleeding or recurrent infection umbilical sinus fistula this is a persistent connection between the umbilical area and the abdominal cavity it can lead to recurrent infections or leakage of abdominal contents umbilical artery vein anomalies the persistent pulse could indicate a vascular anomaly that needs further investigation delayed healing this can increase the risk of complications like scarring hernia development at the site and recurrent infections possible counselling options for the mother the counselling should be empathetic clear and straightforward you should 1 explain the seriousness of the situation emphasize that the wet pulsating cord is abnormal and requires immediate attention to prevent serious infection 2 explain the potential complications clearly outline the risks of infection sepsis and other potential issues as listed above using language the mother can understand 3 reassure her let her know that early intervention can significantly reduce the risks 4 outline the treatment plan explain the steps involved in cleaning the umbilical stump applying appropriate dressings and administering any prescribed antibiotics 5 emphasize the importance of follow up stress the need for regular check ups to monitor the healing process and detect any signs of infection early 6 address any anxieties or misconceptions the mother might have cultural beliefs or misconceptions about umbilical cord care address these gently and provide evidence based information 7 provide instructions on umbilical cord care reinforce proper hygiene practices to prevent further infection this includes gentle cleaning with clean water keeping the area dry and avoiding the use of traditional remedies that may be harmful 8 explain referral procedures if necessary explain the referral process to a higher level facility if the condition worsens or doesn t improve with treatment 9 provide contact information give the mother your contact information or the clinic s contact information so she can reach you with questions or concerns possible outcomes of treatment the outcome depends on the severity of the infection and how promptly it is treated successful healing with prompt treatment antibiotics if infection is present regular cleaning and dressing the umbilical cord stump should eventually dry and separate completely persistent infection if the infection is not adequately treated it can lead to complications such as sepsis requiring hospitalization and intravenous antibiotics surgical intervention in some cases particularly if there is an umbilical sinus fistula or significant abscess formation surgery may be necessary to drain the abscess or correct the underlying anatomical defect long term complications delayed healing or severe infection can result in scarring umbilical hernia and recurrent infections immediate actions 1 thorough examination assess for signs of infection redness swelling warmth purulent discharge foul odor beyond the described stunk check the baby s vital signs temperature heart rate respiratory rate 2 clean the umbilical stump gently clean the area with sterile water or saline solution avoid using alcohol or hydrogen peroxide which can be irritating 3 apply appropriate dressing a clean dry dressing should be used 4 administer antibiotics if infection is suspected this should be guided by a doctor or senior medical professional antibiotics should not be given without proper examination and diagnosis 5 refer to a higher level facility given the presence of a pulse referral to a facility with better resources and surgical capabilities is highly recommended this is essential for a comprehensive assessment and management of potential underlying causes disclaimer i am an ai and cannot provide medical advice the information above is for educational purposes only the mother and baby need immediate medical attention from a qualified healthcare professional\",\n          \"based on the symptoms and physical examination findings i ll provide guidance on investigations and management investigations considering the patient s symptoms particularly the pale palms and eyes i suspect anemia might be a contributing factor given the patient s diet which is high in processed foods and low in essential nutrients iron deficiency anemia is a possibility 1 hemoglobin hb test this is a must do to rule out anemia a low hb level will support the diagnosis of anemia 2 complete blood count cbc this will provide more information on the patient s blood profile including red blood cell indices white blood cell count and platelet count 3 reticulocyte count this test will help determine if the bone marrow is responding to the anemia by producing more red blood cells 4 urinalysis although not directly related to the presenting symptoms a urinalysis can help identify any underlying urinary tract infections or proteinuria which might be contributing to the anemia management 1 dietary counseling educate the patient on the importance of a balanced diet rich in iron folate and vitamin b12 encourage her to consume more fruits vegetables whole grains and lean proteins 2 iron supplementation if the hb test confirms anemia prescribe oral iron supplements e g ferrous sulfate 200mg twice daily to replenish iron stores 3 follow up schedule a follow up appointment in 2 3 weeks to reassess the patient s symptoms and review the hb test results 4 referral if the patient s symptoms persist or worsen or if the anemia is severe consider referring her to a higher level facility for further evaluation and management additional considerations encourage the patient to increase her fluid intake to prevent dehydration which might exacerbate the symptoms if the patient is menstruating consider the possibility of menstrual blood loss contributing to the anemia remember to follow the kenya national guidelines for the management of anemia in adults and children 2016 and the kenya essential medicines list 2016 when managing this patient please let me know if you have any further questions or concerns\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train_formatted"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-559d0e31-118c-48bf-91d7-066602741004\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Master_Index</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Clinician</th>\n",
              "      <th>GPT4.0</th>\n",
              "      <th>LLAMA</th>\n",
              "      <th>GEMINI</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
              "      <td>given your vast experience as a nurse in uasin...</td>\n",
              "      <td>1 immediate treatment protocol for second degr...</td>\n",
              "      <td>here s a response addressing the questions reg...</td>\n",
              "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
              "      <td>given your vast experience as a nurse in uasin...</td>\n",
              "      <td>1 immediate treatment protocol for second degr...</td>\n",
              "      <td>here s a response addressing the questions reg...</td>\n",
              "      <td>given your vast experience as a nurse in uasin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
              "      <td>given your vast experience as a nurse in uasin...</td>\n",
              "      <td>1 immediate treatment protocol for second degr...</td>\n",
              "      <td>here s a response addressing the questions reg...</td>\n",
              "      <td>1 immediate treatment protocol for second degr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
              "      <td>given your vast experience as a nurse in uasin...</td>\n",
              "      <td>1 immediate treatment protocol for second degr...</td>\n",
              "      <td>here s a response addressing the questions reg...</td>\n",
              "      <td>here s a response addressing the questions reg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_XMBBY</td>\n",
              "      <td>i am a nurse with 17 years of experience in ge...</td>\n",
              "      <td>summary 6 year old present with vomiting and a...</td>\n",
              "      <td>clinical summary • a 6 year old girl with know...</td>\n",
              "      <td>based on the symptoms and signs you ve describ...</td>\n",
              "      <td>based on the presentation the 6 year old girl ...</td>\n",
              "      <td>summary 6 year old present with vomiting and a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-559d0e31-118c-48bf-91d7-066602741004')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-559d0e31-118c-48bf-91d7-066602741004 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-559d0e31-118c-48bf-91d7-066602741004');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2f1020dd-a9eb-4d66-b177-98da2ca5ffe4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f1020dd-a9eb-4d66-b177-98da2ca5ffe4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2f1020dd-a9eb-4d66-b177-98da2ca5ffe4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  Master_Index                                             Prompt  \\\n",
              "0     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "1     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "2     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "3     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "4     ID_XMBBY  i am a nurse with 17 years of experience in ge...   \n",
              "\n",
              "                                           Clinician  \\\n",
              "0  summary a 4 year old with 5 superficial burns ...   \n",
              "1  summary a 4 year old with 5 superficial burns ...   \n",
              "2  summary a 4 year old with 5 superficial burns ...   \n",
              "3  summary a 4 year old with 5 superficial burns ...   \n",
              "4  summary 6 year old present with vomiting and a...   \n",
              "\n",
              "                                              GPT4.0  \\\n",
              "0  given your vast experience as a nurse in uasin...   \n",
              "1  given your vast experience as a nurse in uasin...   \n",
              "2  given your vast experience as a nurse in uasin...   \n",
              "3  given your vast experience as a nurse in uasin...   \n",
              "4  clinical summary • a 6 year old girl with know...   \n",
              "\n",
              "                                               LLAMA  \\\n",
              "0  1 immediate treatment protocol for second degr...   \n",
              "1  1 immediate treatment protocol for second degr...   \n",
              "2  1 immediate treatment protocol for second degr...   \n",
              "3  1 immediate treatment protocol for second degr...   \n",
              "4  based on the symptoms and signs you ve describ...   \n",
              "\n",
              "                                              GEMINI  \\\n",
              "0  here s a response addressing the questions reg...   \n",
              "1  here s a response addressing the questions reg...   \n",
              "2  here s a response addressing the questions reg...   \n",
              "3  here s a response addressing the questions reg...   \n",
              "4  based on the presentation the 6 year old girl ...   \n",
              "\n",
              "                                                text  \n",
              "0  summary a 4 year old with 5 superficial burns ...  \n",
              "1  given your vast experience as a nurse in uasin...  \n",
              "2  1 immediate treatment protocol for second degr...  \n",
              "3  here s a response addressing the questions reg...  \n",
              "4  summary 6 year old present with vomiting and a...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train_temp = pd.read_csv(os.path.join(DATASETS_PATH,\"train_dataset.csv\"),\n",
        "                           usecols=['Master_Index', 'Prompt','Clinician', 'GPT4.0', 'LLAMA', 'GEMINI' ]\n",
        "                          )\n",
        "df_train_formatted = expand_df(df_train_temp, template)\n",
        "df_train_formatted.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7MP93889REqw",
        "outputId": "675b08aa-cf83-4c36-d6bc-01fe06c645f0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train_new\",\n  \"rows\": 1376,\n  \"fields\": [\n    {\n      \"column\": \"Master_Index\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"ID_GRATU\",\n          \"ID_VBULH\",\n          \"ID_WQTSF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 344,\n        \"samples\": [\n          \"i am a nurse with 17 years of experience in general nursing working in a dispensaries and private clinics in kakamega county in kenya a client age 24 years a male came in unconscious accompanied with a cook he was a kmtc student who had a history of having only one meal per day rbs done sugars were 2 mrdt was negative and vital signs were normal what can i do to raise sugars can i do guiding and counselling on feeding practices\",\n          \"i am a nurse with 1 years of experience in general nursing working in a sub county hospitals and nursing homes in uasin gishu county in kenya a 65 year old male is brought to the facility with complains of worsening shortness of breath fatigue and lower extremity edema for the past 3 days he has history of chronic heart failure with non compliance to medications and dietary restrictions on assessment bp 160 90mmhg hr 112b min resp 25b min spo2 82 lung auscultation crackles heard questions what is the immediate management what is the pathophysiology of chronic heart failure what is the health education for the patient on drug compliance\",\n          \"i am a nurse with 24 years of experience in general nursing working in a health centres in uasin gishu county in kenya a 27 year old male is brought to the clinic complaining of constipation he says he took a mixture of maize and beans \\u2013 \\u2018githeri\\u2019 \\u2013 for lunch he is a casual laborer in a construction company vital signs temp 360 c pulse \\u2013 90 resp \\u2013 28 questions what is the diagnosis what is the treatment what investigations are necessary for him\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clinician\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1376,\n        \"samples\": [\n          \"this situation requires immediate and careful action the priority for the 7 year old girl is her immediate physical and psychological well being this is a serious case that falls under gender based violence gbv priority treatment 1 stabilize the patient address the immediate physical needs this includes stop the bleeding clean the vaginal area gently and apply appropriate dressings to control bleeding do not insert anything into the vagina pain management administer analgesics as needed appropriate for her age and weight assess for other injuries a thorough physical examination is crucial to identify any other injuries including internal injuries this may require referral to a hospital with better facilities iv fluids if she is showing signs of dehydration or shock administer iv fluids prophylactic antibiotics consider prophylactic antibiotics to prevent infection given the lacerations and bleeding this should be guided by local guidelines and antibiotic sensitivity patterns sti testing and prophylaxis obtain samples for sexually transmitted infection sti testing including hiv syphilis etc and provide appropriate prophylaxis this needs to be done according to local protocols 2 referral immediately refer the girl to a hospital with specialized pediatric care and capacity for managing sexual assault cases she will likely need forensic examination a comprehensive forensic examination is crucial to collect evidence for potential legal proceedings this examination should be conducted by a trained professional specialized medical care this may include surgery to repair lacerations if necessary psychological support a child psychologist or psychiatrist is essential to provide trauma informed care and support 3 ongoing monitoring closely monitor her condition for any complications like infection or psychological distress gbv classification yes this unequivocally falls under gender based violence gbv the sexual assault of a child is a severe form of gbv and it s crucial to treat it as such p3 forms in kenya a p3 form is a medical report used in legal processes related to assault yes you should document this case meticulously in a p3 form accurate documentation is critical for legal proceedings and to ensure justice for the child make sure you document the nature of the injuries the circumstances surrounding the assault as reported by the uncle the girl\\u2019s statement if she is able to provide one remember to be sensitive and avoid leading questions any other relevant information important considerations child protection the safety and well being of the child are paramount you should work with child protection services to ensure she is placed in a safe environment consider reporting to the relevant authorities immediately confidentiality maintain strict confidentiality throughout the process support for the uncle while the focus must be on the child offering the uncle support might lead to him being more cooperative collaboration work closely with other healthcare professionals law enforcement and child protection agencies to ensure the child receives the best possible care and justice this situation requires immediate action act swiftly and decisively prioritizing the child\\u2019s physical and psychological well being while ensuring the appropriate legal and investigative steps are taken do not hesitate to seek assistance from your supervisors and other professionals with expertise in gbv and child sexual assault\",\n          \"this case presents a concerning situation a one month old infant with a persistently wet and pulsating umbilical cord stump this strongly suggests a failure of umbilical cord separation and potentially a serious underlying condition possible risks involved infection omphalitis this is the most immediate and significant risk a wet pulsating cord is a breeding ground for bacteria infection can spread locally causing cellulitis and abscess formation or systemically leading to sepsis a life threatening bloodstream infection the presence of a pulse indicates potential vascular involvement increasing the severity of infection risk umbilical granuloma while less serious than omphalitis a granuloma is a persistent inflamed nodule at the umbilical site it can be a source of bleeding or recurrent infection umbilical sinus fistula this is a persistent connection between the umbilical area and the abdominal cavity it can lead to recurrent infections or leakage of abdominal contents umbilical artery vein anomalies the persistent pulse could indicate a vascular anomaly that needs further investigation delayed healing this can increase the risk of complications like scarring hernia development at the site and recurrent infections possible counselling options for the mother the counselling should be empathetic clear and straightforward you should 1 explain the seriousness of the situation emphasize that the wet pulsating cord is abnormal and requires immediate attention to prevent serious infection 2 explain the potential complications clearly outline the risks of infection sepsis and other potential issues as listed above using language the mother can understand 3 reassure her let her know that early intervention can significantly reduce the risks 4 outline the treatment plan explain the steps involved in cleaning the umbilical stump applying appropriate dressings and administering any prescribed antibiotics 5 emphasize the importance of follow up stress the need for regular check ups to monitor the healing process and detect any signs of infection early 6 address any anxieties or misconceptions the mother might have cultural beliefs or misconceptions about umbilical cord care address these gently and provide evidence based information 7 provide instructions on umbilical cord care reinforce proper hygiene practices to prevent further infection this includes gentle cleaning with clean water keeping the area dry and avoiding the use of traditional remedies that may be harmful 8 explain referral procedures if necessary explain the referral process to a higher level facility if the condition worsens or doesn t improve with treatment 9 provide contact information give the mother your contact information or the clinic s contact information so she can reach you with questions or concerns possible outcomes of treatment the outcome depends on the severity of the infection and how promptly it is treated successful healing with prompt treatment antibiotics if infection is present regular cleaning and dressing the umbilical cord stump should eventually dry and separate completely persistent infection if the infection is not adequately treated it can lead to complications such as sepsis requiring hospitalization and intravenous antibiotics surgical intervention in some cases particularly if there is an umbilical sinus fistula or significant abscess formation surgery may be necessary to drain the abscess or correct the underlying anatomical defect long term complications delayed healing or severe infection can result in scarring umbilical hernia and recurrent infections immediate actions 1 thorough examination assess for signs of infection redness swelling warmth purulent discharge foul odor beyond the described stunk check the baby s vital signs temperature heart rate respiratory rate 2 clean the umbilical stump gently clean the area with sterile water or saline solution avoid using alcohol or hydrogen peroxide which can be irritating 3 apply appropriate dressing a clean dry dressing should be used 4 administer antibiotics if infection is suspected this should be guided by a doctor or senior medical professional antibiotics should not be given without proper examination and diagnosis 5 refer to a higher level facility given the presence of a pulse referral to a facility with better resources and surgical capabilities is highly recommended this is essential for a comprehensive assessment and management of potential underlying causes disclaimer i am an ai and cannot provide medical advice the information above is for educational purposes only the mother and baby need immediate medical attention from a qualified healthcare professional\",\n          \"based on the symptoms and physical examination findings i ll provide guidance on investigations and management investigations considering the patient s symptoms particularly the pale palms and eyes i suspect anemia might be a contributing factor given the patient s diet which is high in processed foods and low in essential nutrients iron deficiency anemia is a possibility 1 hemoglobin hb test this is a must do to rule out anemia a low hb level will support the diagnosis of anemia 2 complete blood count cbc this will provide more information on the patient s blood profile including red blood cell indices white blood cell count and platelet count 3 reticulocyte count this test will help determine if the bone marrow is responding to the anemia by producing more red blood cells 4 urinalysis although not directly related to the presenting symptoms a urinalysis can help identify any underlying urinary tract infections or proteinuria which might be contributing to the anemia management 1 dietary counseling educate the patient on the importance of a balanced diet rich in iron folate and vitamin b12 encourage her to consume more fruits vegetables whole grains and lean proteins 2 iron supplementation if the hb test confirms anemia prescribe oral iron supplements e g ferrous sulfate 200mg twice daily to replenish iron stores 3 follow up schedule a follow up appointment in 2 3 weeks to reassess the patient s symptoms and review the hb test results 4 referral if the patient s symptoms persist or worsen or if the anemia is severe consider referring her to a higher level facility for further evaluation and management additional considerations encourage the patient to increase her fluid intake to prevent dehydration which might exacerbate the symptoms if the patient is menstruating consider the possibility of menstrual blood loss contributing to the anemia remember to follow the kenya national guidelines for the management of anemia in adults and children 2016 and the kenya essential medicines list 2016 when managing this patient please let me know if you have any further questions or concerns\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train_new"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d2ded32c-b990-4bdc-aafe-87fd926585ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Master_Index</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Clinician</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>given your vast experience as a nurse in uasin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>1 immediate treatment protocol for second degr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_VBWWP</td>\n",
              "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
              "      <td>here s a response addressing the questions reg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_XMBBY</td>\n",
              "      <td>i am a nurse with 17 years of experience in ge...</td>\n",
              "      <td>summary 6 year old present with vomiting and a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2ded32c-b990-4bdc-aafe-87fd926585ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2ded32c-b990-4bdc-aafe-87fd926585ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2ded32c-b990-4bdc-aafe-87fd926585ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-da12fcea-f9f5-4731-885a-ee81ef71f1e5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da12fcea-f9f5-4731-885a-ee81ef71f1e5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-da12fcea-f9f5-4731-885a-ee81ef71f1e5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  Master_Index                                             Prompt  \\\n",
              "0     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "1     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "2     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "3     ID_VBWWP  i am a nurse with 18 years of experience in ge...   \n",
              "4     ID_XMBBY  i am a nurse with 17 years of experience in ge...   \n",
              "\n",
              "                                           Clinician  \n",
              "0  summary a 4 year old with 5 superficial burns ...  \n",
              "1  given your vast experience as a nurse in uasin...  \n",
              "2  1 immediate treatment protocol for second degr...  \n",
              "3  here s a response addressing the questions reg...  \n",
              "4  summary 6 year old present with vomiting and a...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train_new = df_train_formatted[[\"Master_Index\", \"Prompt\", \"text\"]].rename(columns={\"text\": \"Clinician\"})\n",
        "df_train_new.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T21:40:37.406431Z",
          "iopub.status.busy": "2025-04-20T21:40:37.405757Z",
          "iopub.status.idle": "2025-04-20T21:40:37.413159Z",
          "shell.execute_reply": "2025-04-20T21:40:37.412497Z",
          "shell.execute_reply.started": "2025-04-20T21:40:37.406409Z"
        },
        "id": "9yJd-fCHdbSK",
        "outputId": "00b03083-24e2-4fd7-d325-166860f369d0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_validation_raw\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"Master_Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"ID_OHZDT\",\n          \"ID_DGQWO\",\n          \"ID_CEGVK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"i am a nurse with 8 years of experience in general nursing working in a sub county hospitals and nursing homes in kakamega county in kenya a patient with burns over the chest and face present in casualty the patient develops difficulty in breathing while at the department vital signs are within normal range except the spo2 which is 89 of oxygen and respiration that is 24 breaths per minute why is the patient having difficulty in breathing what is the appropriate position for this patient should i de blister the patient\",\n          \"i am a nurse with 20 years of experience in primary care working in a national referral hospitals in uasin gishu county in kenya a female patient age 27 years is admitted to the ward after acdf surgery the general condition is stable with vital stable the hb done is at 7g dl blood was ordered for grouping and cross matched and transfusion was done after 15 minutes the patient reported itching in the whole body hotness of the body and palpitations questions x0001 what is the immediate action to be taken x0001 what protocol should be followed if it is a case of blood transfusion x0001 what investigations need to be done\",\n          \"i am a nurse with 18 years of experience in general nursing working in a national referral hospitals in uasin gishu county in kenya a 20 year old female patient came to the hospital with complaints of severe lower abdominal for 2 days she is nulliparous she had been in marriage for 2 years without a baby she bought medicines in a clinic and she was told they are fertility drugs vital signs temperature 36 60c pulse 121 beats minute respiration 16 breaths minute question s what is the differential diagnosis what investigations can be done\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clinician\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"summary a patient with burns on chest and face develops difficulty in breathing spo2 89 respiratory rate 24 other vitals normal 1 why is the patient having difficulty in breathing inhalation injury may occur when burns affect the face causing difficulty in breathing 2 what is the appropriate position for this patient patients with inhalation injuries are kept in a supine position with oxygen supplied to them via face mask 3 should i de blister the patient yes\",\n          \"summary a 27 year old female admitted after acdf surgery with stable vitals hb done 7g dl blood ordered and transfused after 15 minutes she reported itching in the whole body hotnesso f body and palpitations what is the immediate action to be taken stop the transfusion immediately give antihistamine intravenously stat example hydrocortisone if you have adrenaline it can be given antipyretic for fever analgesic to reduce pain close monitoring of patient vitals report to the lab and redo the cross match for further evaluation what protocol should be followed if it is a case of blood transfusion report to the lab and take the blood back for further evaluation recheck grouping and cross matching investigations grouping and cross matching diagnosis blood transfusion reaction\",\n          \"a 20 year old female patient with complaints of severe lower abdominal pain for 1 2 days she is nulliparous and has been in marriage for 2 years without a baby she bought medicine which were fertility drugs vitals 36 6 temp pulse 121 bpm resp 16 bpm lab investigations to be done complete blood count urea creatinine and electrolytes urinalysis pregnancy diagnostic test blood grouping and crossmatching radiological abdominopelvic ultrasound erect abdominal x ray\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_validation_raw"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-da87f058-a6a9-4c06-8e12-9b5946a0b3c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Master_Index</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Clinician</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_OHZDT</td>\n",
              "      <td>i am a nurse with 8 years of experience in gen...</td>\n",
              "      <td>summary a patient with burns on chest and face...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_DGQWO</td>\n",
              "      <td>i am a nurse with 20 years of experience in pr...</td>\n",
              "      <td>summary a 27 year old female admitted after ac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da87f058-a6a9-4c06-8e12-9b5946a0b3c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da87f058-a6a9-4c06-8e12-9b5946a0b3c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da87f058-a6a9-4c06-8e12-9b5946a0b3c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-44be4300-acc8-4d2a-bc1a-cf72bd9ea787\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44be4300-acc8-4d2a-bc1a-cf72bd9ea787')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-44be4300-acc8-4d2a-bc1a-cf72bd9ea787 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  Master_Index                                             Prompt  \\\n",
              "0     ID_OHZDT  i am a nurse with 8 years of experience in gen...   \n",
              "1     ID_DGQWO  i am a nurse with 20 years of experience in pr...   \n",
              "\n",
              "                                           Clinician  \n",
              "0  summary a patient with burns on chest and face...  \n",
              "1  summary a 27 year old female admitted after ac...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_validation_raw.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T21:41:10.305531Z",
          "iopub.status.busy": "2025-04-20T21:41:10.304835Z",
          "iopub.status.idle": "2025-04-20T21:41:10.347401Z",
          "shell.execute_reply": "2025-04-20T21:41:10.346609Z",
          "shell.execute_reply.started": "2025-04-20T21:41:10.305507Z"
        },
        "id": "0cA2cS6LdbSK",
        "outputId": "9116a9f8-3357-456b-9a5e-e1698dac88d0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example formatted text: {'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou are a clinical reasoning assistant trained to help diagnose medical conditions. Provide detailed, evidence-based assessments. Always consider patient safety first.<|eot_id|><|start_header_id|>user<|end_header_id|>\\ni am a nurse with 18 years of experience in general nursing working in a sub county hospitals and nursing homes in uasin gishu county in kenya a 4 year old child presents to the emergency department with second degree burns on the forearm after accidentally touching a hot stove the child was playing in the kitchen when they reached out to touch the stove the burns cover about 5 of the total body surface area the child is alert and crying with redness blisters and swelling on the affected area the burns appear to be superficial to moderate in severity the child is in mild pain and there is no indication of airway or breathing distress no other injuries are noted questions 1 what is the immediate treatment protocol for second degree burns in paediatric patients 2 should any tetanus prophylaxis be considered in this case 3 what follow up care should be recommended for burn healing<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nsummary a 4 year old with 5 superficial burns no other injuries immediate management paracetamol analgesics to to ensure child has minimal or no pain cleaning and frosting of wound with silver sulpha fizika topical prophylactic can be considered in this case good nutrition high protein diet<|eot_id|>'}\n"
          ]
        }
      ],
      "source": [
        "# Create formatted dataset\n",
        "# formated_train_dataset = format_data_llama_3(dataset=Dataset.from_pandas(df_train_raw),\n",
        "formated_train_dataset = format_data_llama_3(dataset=Dataset.from_pandas(df_train_new),\n",
        "prompt_column_name= \"Prompt\",\n",
        "response_column_name= \"Clinician\",\n",
        "system_prompt=None\n",
        ")\n",
        "\n",
        "formated_validation_dataset = format_data_llama_3(dataset=Dataset.from_pandas(df_validation_raw),\n",
        "prompt_column_name= \"Prompt\",\n",
        "response_column_name= \"Clinician\",\n",
        "system_prompt=None\n",
        ")\n",
        "\n",
        "print(f\"Example formatted text: {formated_train_dataset[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQDJx24dbSK"
      },
      "source": [
        "# Setup Finetune: Model Configuration\n",
        "---\n",
        "**Base models**\n",
        "1. \"unsloth/Llama-3.2-1B-bnb-4bit\",          \n",
        "2. \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "3. \"meta-llama/Llama-3.2-1B\"\n",
        "4. \"unsloth/Llama-3.2-1B-Instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T20:21:30.844701Z",
          "iopub.status.busy": "2025-04-20T20:21:30.844122Z",
          "iopub.status.idle": "2025-04-20T20:21:30.852375Z",
          "shell.execute_reply": "2025-04-20T20:21:30.851786Z",
          "shell.execute_reply.started": "2025-04-20T20:21:30.844678Z"
        },
        "id": "OTJmya6ddbSK",
        "outputId": "a744173e-13d1-4c2a-c8a9-003b0e2acf16",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_size': 2,\n",
              " 'epochs': 3,\n",
              " 'gradient_accumulation_steps': 1,\n",
              " 'learning_rate': 5e-05,\n",
              " 'lr_scheduler': 'cosine',\n",
              " 'optim': 'adamw_torch',\n",
              " 'output_dir': '/content/workspace/models/finetuned-model',\n",
              " 'warmup_ratio': 0.03,\n",
              " 'weight_decay': 0.01}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load configurations\n",
        "finetune_config: dict  = load_config(path=latest_config_version_path)\n",
        "\n",
        "finetune_config.get('training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "ab2dca7bb9a249ccb75423786d8c50fc",
            "7ebe07334cf54215acf77d2ff1146e8f",
            "9ad866b3cffe4ef597f48c0dc5c13e22",
            "c9f725be622a4f148b122a4d769845a1",
            "030143feaa764f8699382ed77fa64726",
            "3c2b055fa7b14568b0d899246088ea17",
            "f50601c8e37e4ae18ee1472aff5453b7",
            "1fde00c5a29345dd96753404c7eac2d5",
            "d2a082097e4e42e699e0d8ca75db0452",
            "b17fab78ea3941258d9b75d9cc0512a4",
            "86c9e1b3231c4210951cf17accbced58",
            "f8ae0ffc4ce149a8bca50951437695a5",
            "ee0bafd2bab34790a66bc5642260b7b9",
            "64534362c7db448b9345e23d7a0c3f75",
            "6d880f8aa13c4563978f137b53afd241",
            "22511cc6d54d4a0a8252a6b3e91e8cf1",
            "61aceaf4a0004681beb349fbaedf0fe0",
            "9a6bdbca471046348bea38146b78ddba",
            "f92c590a57324ed8a4a4c4b27379a3c9",
            "591c2a03c9ef4797b81fd573bbac337b",
            "08e66b003a5b4a1c97ed06f34e98d371",
            "1f353c9c9ccc49bb9232dc9365e3a98a",
            "b109e5c94a164520bcc6e1836cfc214b",
            "e531e3fbe0b64a46a4adf5d9d04fe884",
            "87f1f03e98c54b9696ec8a1d08dc612f",
            "1da2631b0c14493bb8cddc1f1dc6c243",
            "85dad603d3804acca9cc28e1374ead63",
            "6b206a319ec04f1a9f28e3e6d45cc224",
            "28eb1248b4fe4020937c977333d4a47a",
            "148b1f5171f24a0082de921b963286d2",
            "63c7ae9f2adf494a99fdcb3afad21a96",
            "8e512981e44a40008ee921612271bfc4",
            "2e6c3259054e4f028079d516316fde8a",
            "ed261e7d192445b0b89a0400b4b6bdd7",
            "456ab4165b5f40a882f5db5e47c5b13e",
            "9a1eed9965804dc4966d31f010ffc43b",
            "7deb31e3f56e47a8a02225952c0eab84",
            "52334b5816f84059a4df44d519b427d3",
            "3629d2fa15fd4a29870ae8979a76cff6",
            "06a2c21f7bca4cf3b0f5a9a944302068",
            "53190e4d69cd47bf9be2550b356211ef",
            "4ae3ed1b6a5e432ebf412638354e0174",
            "1b04a2f923c545a1b1507812ed784f27",
            "0c8ecbba73d84886a9b4e7ad9d12e317",
            "50e67a287d3b4ddd8a10daaa7a0caf09",
            "16fc24644d9c4f59b95fd38912281f3c",
            "84d35236c71549ef94405fdabad742f0",
            "c986a538f1a34408acbb4540a2aa9ccc",
            "f29ff94f3ba041f69d28a69aa43207af",
            "624dbc94f5ad4eca8bb35fe5ba322691",
            "fc45fb0df04644049fd5302a46699938",
            "1022bc51f3f0465597992514df0a7f55",
            "cf950cf057fa428ea8d16e1395fce44e",
            "5c037846b19743f896b6b4b61f01d721",
            "6b0a1164d4434cb9b22e5cc339e89399"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T20:20:03.819312Z",
          "iopub.status.busy": "2025-04-20T20:20:03.819051Z",
          "iopub.status.idle": "2025-04-20T20:20:13.526686Z",
          "shell.execute_reply": "2025-04-20T20:20:13.525301Z",
          "shell.execute_reply.started": "2025-04-20T20:20:03.819290Z"
        },
        "id": "LouLSTfodbSK",
        "outputId": "27af0548-b085-4cc4-8de0-5edc918b5b12",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.5.7: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab2dca7bb9a249ccb75423786d8c50fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8ae0ffc4ce149a8bca50951437695a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b109e5c94a164520bcc6e1836cfc214b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed261e7d192445b0b89a0400b4b6bdd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50e67a287d3b4ddd8a10daaa7a0caf09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "                    model_name = finetune_config.get('model').get('base_model'),\n",
        "                    max_seq_length = finetune_config.get('model').get('max_seq_length',2048),\n",
        "                    dtype = finetune_config.get('model').get('dtype', torch.bfloat16),\n",
        "                    load_in_4bit =finetune_config.get('model').get('load_in_4bit', True),\n",
        "                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T20:42:23.771551Z",
          "iopub.status.busy": "2025-04-20T20:42:23.771298Z",
          "iopub.status.idle": "2025-04-20T20:42:23.782548Z",
          "shell.execute_reply": "2025-04-20T20:42:23.781900Z",
          "shell.execute_reply.started": "2025-04-20T20:42:23.771535Z"
        },
        "id": "O-Z0CgUndbSL",
        "outputId": "6db99623-9f5b-44e2-c6a4-dd9da56c0b33",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
            "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
            "Unsloth 2025.5.7 patched 16 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 8,650,752 || all params: 1,244,465,152 || trainable%: 0.6951\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = finetune_config.get('lora').get('r', 16),                      # Suggested 8, 16, 32, 64, 128\n",
        "    lora_alpha = finetune_config.get('lora').get('alpha', 32),         # Suggested lora_alpha = 2 x r\n",
        "    target_modules = finetune_config.get('lora').get('target_modules'),\n",
        "    lora_dropout = finetune_config.get('lora').get('dropout',0),       # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",                                                     # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\",                            # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,                                                # We support rank stabilized LoRA\n",
        "    loftq_config = None,                                               # And LoftQ\n",
        ")\n",
        "\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvH2PRc1dbSL"
      },
      "source": [
        "## Create model specific chat template\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T21:38:10.073107Z",
          "iopub.status.busy": "2025-04-20T21:38:10.072560Z",
          "iopub.status.idle": "2025-04-20T21:38:10.077439Z",
          "shell.execute_reply": "2025-04-20T21:38:10.076721Z",
          "shell.execute_reply.started": "2025-04-20T21:38:10.073082Z"
        },
        "id": "GoVeHwmodbSL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = finetune_config.get('tokenizer').get('chat_template'),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XiR7tnadbSL"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-20T20:21:34.567449Z",
          "iopub.status.busy": "2025-04-20T20:21:34.566757Z",
          "iopub.status.idle": "2025-04-20T20:21:34.602770Z",
          "shell.execute_reply": "2025-04-20T20:21:34.602256Z",
          "shell.execute_reply.started": "2025-04-20T20:21:34.567426Z"
        },
        "id": "P-RhcQWAdbSL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# set training args, comment out paramenters to use default config values.\n",
        "training_args = SFTConfig(\n",
        "    output_dir = finetune_config.get(\"training\").get(\"output_dir\"),\n",
        "    num_train_epochs= finetune_config.get(\"training\").get(\"epochs\"),\n",
        "    per_device_train_batch_size= finetune_config.get(\"training\").get(\"batch_size\"),\n",
        "    gradient_accumulation_steps= finetune_config.get(\"training\").get(\"gradient_accumulation_steps\"),\n",
        "    optim= finetune_config.get(\"training\").get(\"optim\"),\n",
        "    learning_rate= finetune_config.get(\"training\").get(\"learning_rate\"),\n",
        "    lr_scheduler_type= finetune_config.get(\"training\").get(\"lr_scheduler\"),\n",
        "    warmup_ratio= finetune_config.get(\"training\").get(\"warmup_ratio\"),\n",
        "    weight_decay= finetune_config.get(\"training\").get(\"weight_decay\"),\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    gradient_checkpointing=True,\n",
        "    # evaluation_strategy=finetune_config.get(\"evaluation\").get(\"strategy\"),\n",
        "    eval_steps=finetune_config.get(\"evaluation\").get(\"eval_steps\"),\n",
        "    save_steps=finetune_config.get(\"evaluation\").get(\"save_steps\"),\n",
        "    save_total_limit=finetune_config.get(\"evaluation\").get(\"save_total_limit\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6FtNNcKdbSL"
      },
      "source": [
        "## Train and save model checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-20T21:30:57.656323Z",
          "iopub.status.busy": "2025-04-20T21:30:57.655703Z",
          "iopub.status.idle": "2025-04-20T21:30:57.661271Z",
          "shell.execute_reply": "2025-04-20T21:30:57.660568Z",
          "shell.execute_reply.started": "2025-04-20T21:30:57.656289Z"
        },
        "id": "4kgKsDCxdbSL",
        "outputId": "a406b7c9-bb03-4380-c7bd-b56650d7be72",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "4.846 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twZIe7HWXLdS"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "3c4702d772c74902966728b4979b473e",
            "24a4739fb7a54ecc9f6e9ebecd68861b",
            "bf37c7ae1dcf482592d29bcbcfa4433a",
            "a9b220c1996445eea3e0c716105f23af",
            "2b8f51849dbf4fc6a5f72668bd790dd0",
            "5d21c25a10b646c5b129a4ad7513e719",
            "ec20538d04e74678bcbc8e9e07a42ef3",
            "350c0295cee84d26b9ec566a75238ff1",
            "7ee4f567699646da8e3daa8accc9d367",
            "ef137c61bec74e9b91d38bbc12f320c9",
            "e63defbe745441cbbd1ddb3c40dffd36",
            "d7532021e92748f5805395af7312f5c8",
            "9042ac43ba094748b7e5c6cf7ac64bd5",
            "9908245dc72d43388554b506d956a97d",
            "5824e2e912e7469990e9ab7fe17cdc18",
            "f7f0aa5872a44350abd5c635c415adb5",
            "905aa4183abb4df0972a6b04f489becd",
            "4bc4bd2d65a74359b74bcf1f2ea58f2b",
            "9789a31798824be98ade4e68144a1b59",
            "fc66827777e74254a5fb62f2197d2f9c",
            "b0108ae173c24536b3c35e01b693e03b",
            "12b4a9d97b6740cd85b6e0cf619ac077"
          ]
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-20T21:42:42.423783Z",
          "iopub.status.busy": "2025-04-20T21:42:42.423499Z"
        },
        "id": "UgSGTqGhdbSL",
        "outputId": "0e8388d7-b22b-45e7-b1a9-9c35469c2c51",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c4702d772c74902966728b4979b473e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/1376 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7532021e92748f5805395af7312f5c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/18 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 1,376 | Num Epochs = 3 | Total steps = 2,064\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
            " \"-____-\"     Trainable parameters = 8,650,752/1,244,465,152 (0.70% trained)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='2064' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  39/2064 00:30 < 27:39, 1.22 it/s, Epoch 0.06/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.526600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.693500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.477600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-fb883734ece3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Finetune model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_patched_step_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset= formated_train_dataset,\n",
        "    eval_dataset=  formated_validation_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    args= training_args,\n",
        "    packing=True,\n",
        "    max_seq_length=2048,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "# Finetune model\n",
        "trainer_stats = trainer.train()\n",
        "\n",
        "# Save model\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKOCx6pNdbSL",
        "outputId": "bbd359c3-1f2e-4857-81f0-aa2db6dd2979",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "4.846 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haWh-t2gdbSL"
      },
      "source": [
        "# Model Evaluation\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj1MzdrhdbSM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This metric computes the average ROUGE-L F1 score between the predicted clinician response\n",
        "and the expert reference response. ROUGE-L captures the longest common subsequence between\n",
        "two texts, making it suitable for evaluating structured clinical answers.\n",
        "\n",
        "Required columns:\n",
        "- solution: must contain a column named \"reference\"\n",
        "- submission: must contain a column named \"prediction\"\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "def rougel_f1_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
        "    '''\n",
        "    This metric computes the average ROUGE-L F1 score between the predicted clinician response\n",
        "    and the expert reference response. ROUGE-L captures the longest common subsequence between\n",
        "    two texts, making it suitable for evaluating structured clinical answers.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    - solution (pd.DataFrame): DataFrame must contain a column named \"reference\"\n",
        "    - submission (pd.DataFrame): DataFrame must contain a column named \"prediction\"\n",
        "    - row_id_column_name (str): ID column name to align records from both dataframes.\n",
        "\n",
        "    Returns: Average F1 score\n",
        "\n",
        "    PyTest:\n",
        "    -------\n",
        "    >>> import pandas as pd\n",
        "    >>> row_id_column_name = \"id\"\n",
        "    >>> y_true = pd.DataFrame({\"id\": [0], \"Clinician\": [\"The cat sat on the mat.\"]})\n",
        "    >>> y_pred = pd.DataFrame({\"id\": [0], \"Clinician\": [\"The cat sat.\"]})\n",
        "    >>> round(rougel_f1_score(y_true.copy(), y_pred.copy(), row_id_column_name), 4)\n",
        "    0.6667\n",
        "    '''\n",
        "\n",
        "    # set expected y true and y hat column names\n",
        "    _reference_column_name: str = \"Clinician\"\n",
        "    _prediction_column_name: str = \"Clinician\"\n",
        "\n",
        "    if row_id_column_name not in solution.columns or row_id_column_name not in submission.columns:\n",
        "        raise ParticipantVisibleError(f\"Missing ID column '{row_id_column_name}' in either solution or submission.\")\n",
        "\n",
        "    # Align rows by ID\n",
        "    solution = solution.set_index(row_id_column_name).sort_index()\n",
        "    submission = submission.set_index(row_id_column_name).sort_index()\n",
        "\n",
        "    # Check for matching IDs\n",
        "    if not solution.index.equals(submission.index):\n",
        "        raise BaseException(f\"Submission and solution {row_id_column_name} do not match.\")\n",
        "\n",
        "    # Validate column names\n",
        "    if _reference_column_name not in solution.columns:\n",
        "        raise BaseException(f\"Solution dataframe/file must contain a '{_reference_column_name}' column.\")\n",
        "\n",
        "    if _prediction_column_name not in submission.columns:\n",
        "        raise BaseException(f\"Submission dataframe/file must contain a '{_prediction_column_name}' column.\")\n",
        "\n",
        "    references = solution[_reference_column_name].astype(str)\n",
        "    predictions = submission[_prediction_column_name].astype(str)\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
        "\n",
        "    scores = []\n",
        "    for ref, pred in zip(references, predictions):\n",
        "        result = scorer.score(ref, pred)\n",
        "        scores.append(result[\"rougeL\"].fmeasure)\n",
        "\n",
        "    # Safety: check for empty evaluation\n",
        "    if not scores:\n",
        "        raise BaseException(\"No predictions to score.\")\n",
        "\n",
        "    average_f1 = sum(scores) / len(scores)\n",
        "\n",
        "    # Final check: must return a valid float\n",
        "    if not pd.notnull(average_f1) or not (0 <= average_f1 <= 1):\n",
        "        raise BaseException(\"Metric computed an invalid score.\")\n",
        "\n",
        "    return float(average_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BjSyJ-OdbSM"
      },
      "source": [
        "# Model Benchmark inference and submission\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "f251b4a0da9a430cb91739b2ae7d99a5",
            "b18d1f1efa5849bdb1ae524e0cfcabca",
            "7127e4e7b0af4cb6a84a404cb192cb6a",
            "82761c9846854ea1a0b53982899fa5a1",
            "79ba63b23b6f407f8300e8865e1fb86e",
            "e3d3aad420344dcab88701bc086c087f",
            "9bf2b01fc66346758436765a70f7cdc2",
            "21da7ba104414ce69b51e0bc0faac36a",
            "4689f7b1ad44469ca02e73e01cdd3dfb",
            "cbd82f413ee34d13840527c87444e255",
            "5591bdc5056b413ea6d03561dd781ffa",
            "d1f16ed10f104288b5003e7cbde97655",
            "f8f4d9eb48a64a33a51cb0562318de69",
            "0777c7f48ab048e7a3d59d62def95d7b",
            "aee6df096c94467fb500e2094f6606a1",
            "bffb58d39d474c5092b5a63fe99bb83d",
            "2d1a3c0d06a54a6995d94c42d4ec3990",
            "5feeeca2b5d84c7b816e8ca69f9fbf19",
            "e4c5ec705dcb4b9582a8a1569ee27636",
            "a9a79d2679a6406e8cda54eee6811048",
            "28daa403a9004d7990729095c3c86ad5",
            "adfba968acae4276b55a7699aa42ce1c"
          ]
        },
        "id": "VUX-aK-BdbSM",
        "outputId": "2bbce499-9744-4ef8-c349-a83e6c9504c5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.5.7: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f251b4a0da9a430cb91739b2ae7d99a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1f16ed10f104288b5003e7cbde97655",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "max_seq_length = 8192 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = FINETUNED_MODELS_PATH, #\"software-together/model-v2-16bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"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\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JAghNRtpJEQB",
        "outputId": "41fb345e-0e11-4fd0-8d71-f5afa327feb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 2048, padding_idx=128004)\n",
              "        (layers): ModuleList(\n",
              "          (0-15): 16 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.2\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BokAXjvEKHZE"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbeuNlSFPNcf"
      },
      "outputs": [],
      "source": [
        "# study how to do this better\n",
        "instr_prompt2 ={\n",
        "\n",
        "  \"instruction\": \"You are a medical professor and practitioner with over 100 years of experience, specialized in: Maternal and Child Health, Child Health, and Adult Health. You will be given clinical case scenarios by nurses, including nurse background, patient demographics, presenting symptoms, clinical findings, and a clinical question.\\n\\nRespond using this format:\\n\\n1. Categorize the scenario by nursing specialty:\\n   - Maternal and Child Health\\n   - Child Health\\n   - Adult Health\\n\\n2. Provide Differential Diagnoses (DDX) using SNOMED CT:\\n   Format: 'Code | Diagnosis Description (entity type)'\\n\\n3. Follow this Clinical Structure:\\n   - Summary: Recap the case\\n   - Clinical Reasoning: Explain how the symptoms and findings lead to the DDX\\n   - Differential Diagnosis: Include SNOMED CT codes\\n   - Management Plan: What to do next (tests, treatments, referrals)\\n   - Answers to Scenario Questions: Direct, clear responses\\n\\n4. Communication Style:\\n   - Use a human, compassionate, professional tone\\n   - Avoid excessive jargon; be clear and supportive\\n   - Provide answers as an expert guiding junior clinicians or nurses\\n\\nObjective: Respond to each case using deep clinical reasoning, structured planning, and SNOMED CT for medical standardization.\",\n",
        "\n",
        "  \"input\": \"i am a nurse with 17 years of experience in general nursing working in a national referral hospital in uasin gishu county in kenya. a 6-year-old girl presented with vomiting and abdominal pain. she is a known diabetic but has not been taking insulin due to lack of funds. on examination, she is confused, has kussmaul breathing, dry tongue, fruity breath, blurred vision. vitals: T: 37, P: 120, RR: 48, SpO2: 90%. what is the diagnosis? what is the most immediate management? what education is needed? what investigations are required?\",\n",
        "\n",
        "  \"output\": \"summary Child Health\\n\\nSNOMED CT Differential Diagnoses:\\n- 420422005 | Diabetic ketoacidosis (disorder)\\n- 46635009 | Type 1 diabetes mellitus (disorder)\\n\\nSummary: A 6-year-old girl presents with symptoms highly consistent with diabetic ketoacidosis due to insulin non-adherence.\\n\\nClinical Reasoning: The patient’s vomiting, Kussmaul respirations, fruity breath, dehydration, and confusion point to metabolic acidosis caused by DKA.\\n\\nDifferential Diagnosis:\\n- Diabetic ketoacidosis (420422005)\\n- Metabolic acidosis (302866003)\\n- Hypovolemia (271327008)\\n\\nManagement Plan:\\n1. Initiate oxygen therapy immediately\\n2. Start IV fluids (0.9% normal saline bolus 10–20 mL/kg)\\n3. Begin insulin therapy once fluid resuscitation is underway\\n4. Monitor potassium levels and electrolytes\\n5. Admit for close monitoring\\n\\nAnswers to Questions:\\n1. Diagnosis: Diabetic Ketoacidosis\\n2. Immediate Management: Oxygen, fluids, insulin, monitoring\\n3. Education: Importance of insulin adherence, early DKA signs, sick day management, connect to financial/social support\\n4. Investigations: Blood glucose, ketones, venous blood gas, electrolytes, renal function, ECG\"\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPEsdOLQOC2a"
      },
      "outputs": [],
      "source": [
        "instr_prompt = {\n",
        "  \"instruction\": \"You are a medical professor and practitioner with over 100 years of experience across Maternal and Child Health, Child Health, and Adult Health. Given a clinical case scenario from a nurse, categorize the nursing specialty, provide SNOMED CT differential diagnoses, and return a structured expert response.\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4prr7mJhjXqi"
      },
      "outputs": [],
      "source": [
        "def llm_inference(model,\n",
        "                  user_prompts:pd.DataFrame,\n",
        "                  system_prompt: str,\n",
        "                  prompt_column:str='Prompt',\n",
        "                  record_id_column: str ='Master_Index',\n",
        "                  args:dict=None\n",
        "                  )->pd.DataFrame:\n",
        "    \"\"\"Runs inference against the model and returns a dataframe with clinician results.\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for idx, row in user_prompts.iterrows():\n",
        "        prompt = row['Prompt']\n",
        "        master_index = row['Master_Index']\n",
        "\n",
        "        messages = [\n",
        "          {\"role\": \"system\", \"content\": system_prompt},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "          ]\n",
        "\n",
        "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "        outputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1,  temperature = 1.5)\n",
        "\n",
        "        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        result_text = text.split(\"assistant\")[1]\n",
        "        #outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True, temperature = 1.5, min_p = 0.1)\n",
        "        #result_text = tokenizer.batch_decode(outputs)\n",
        "        #print(\"result_text: \",result_text)\n",
        "\n",
        "        results.append({\n",
        "            \"Master_Index\": master_index,\n",
        "            \"Clinician\": result_text\n",
        "        })\n",
        "\n",
        "        time.sleep(0.1)\n",
        "        print(f\"Running so far with {idx} of {len(user_prompts)}: {master_index}\")\n",
        "\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb3mOYj1oXvh",
        "outputId": "c0d50a89-58cb-49a5-f416-33c303571f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running so far with 0 of 18: ID_OHZDT\n",
            "Running so far with 1 of 18: ID_DGQWO\n",
            "Running so far with 2 of 18: ID_PPJVQ\n",
            "Running so far with 3 of 18: ID_TOCCU\n",
            "Running so far with 4 of 18: ID_IYFIZ\n",
            "Running so far with 5 of 18: ID_CVWHT\n",
            "Running so far with 6 of 18: ID_RYKSB\n",
            "Running so far with 7 of 18: ID_PTREU\n",
            "Running so far with 8 of 18: ID_CEGVK\n",
            "Running so far with 9 of 18: ID_CSMTR\n",
            "Running so far with 10 of 18: ID_WTBDF\n",
            "Running so far with 11 of 18: ID_ZQORV\n",
            "Running so far with 12 of 18: ID_GLHTL\n",
            "Running so far with 13 of 18: ID_ZOSDW\n",
            "Running so far with 14 of 18: ID_NVGKJ\n",
            "Running so far with 15 of 18: ID_AUQGT\n",
            "Running so far with 16 of 18: ID_RZPUS\n",
            "Running so far with 17 of 18: ID_BGWLU\n"
          ]
        }
      ],
      "source": [
        "df_validation_predictions = llm_inference(model=model,\n",
        "                                     user_prompts=df_validation_raw[['Master_Index','Prompt']],\n",
        "                                     system_prompt=instr_prompt\n",
        "                                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgfKkPObs15-",
        "outputId": "9c628ed2-b4ca-4f7b-9151-a0b64c9547e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.16160767596599318"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Validation scoring\n",
        "rougel_f1_score(solution=df_validation_raw,\n",
        "                submission=df_validation_predictions,\n",
        "                row_id_column_name=\"Master_Index\"\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YifX3cy0tkm3"
      },
      "source": [
        "## Test Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFlgtv7puOWr"
      },
      "outputs": [],
      "source": [
        "model_name = config_dict.get(\"model\").get('base_model').replace(\"/\",\"-\")\n",
        "run_timestamp = datetime.now().strftime(\"%Y%m%dT%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPbUMSsaLW7E",
        "outputId": "de379b08-6b69-486e-9083-5bd0acc9a276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running so far with 0 of 38: ID_AOANH\n",
            "Running so far with 1 of 38: ID_BKPAH\n",
            "Running so far with 2 of 38: ID_BNHVT\n",
            "Running so far with 3 of 38: ID_CHHIO\n",
            "Running so far with 4 of 38: ID_CZVOY\n",
            "Running so far with 5 of 38: ID_DIXUW\n",
            "Running so far with 6 of 38: ID_EQRHR\n",
            "Running so far with 7 of 38: ID_GERAA\n",
            "Running so far with 8 of 38: ID_GMPJA\n",
            "Running so far with 9 of 38: ID_HXDLY\n",
            "Running so far with 10 of 38: ID_IKDJT\n",
            "Running so far with 11 of 38: ID_JOBAE\n",
            "Running so far with 12 of 38: ID_KCMKY\n",
            "Running so far with 13 of 38: ID_KOKFK\n",
            "Running so far with 14 of 38: ID_LIESO\n",
            "Running so far with 15 of 38: ID_MANPW\n",
            "Running so far with 16 of 38: ID_MDILB\n",
            "Running so far with 17 of 38: ID_MWOML\n",
            "Running so far with 18 of 38: ID_OFZHH\n",
            "Running so far with 19 of 38: ID_OGGLZ\n",
            "Running so far with 20 of 38: ID_OICRH\n",
            "Running so far with 21 of 38: ID_OLABW\n",
            "Running so far with 22 of 38: ID_ONSYX\n",
            "Running so far with 23 of 38: ID_ONVGJ\n",
            "Running so far with 24 of 38: ID_QRYLO\n",
            "Running so far with 25 of 38: ID_RHPMN\n",
            "Running so far with 26 of 38: ID_RSYNM\n",
            "Running so far with 27 of 38: ID_SBFHC\n",
            "Running so far with 28 of 38: ID_SPZRA\n",
            "Running so far with 29 of 38: ID_SUOCB\n",
            "Running so far with 30 of 38: ID_SZZUJ\n",
            "Running so far with 31 of 38: ID_TQTFO\n",
            "Running so far with 32 of 38: ID_VITYK\n",
            "Running so far with 33 of 38: ID_WZVWA\n",
            "Running so far with 34 of 38: ID_XWSYQ\n",
            "Running so far with 35 of 38: ID_YLSDZ\n",
            "Running so far with 36 of 38: ID_YVQUD\n",
            "Running so far with 37 of 38: ID_ZRHBT\n"
          ]
        }
      ],
      "source": [
        "df_test_predictions = llm_inference(model=model,\n",
        "                                     user_prompts=df_test_raw[['Master_Index','Prompt']],\n",
        "                                     system_prompt=instr_prompt2\n",
        "                                     )\n",
        "\n",
        "df_test_predictions.to_csv(f\"{BENCHMARK_PATH}/local_test_{model_name}_{run_timestamp}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v-80XDSMt1nL",
        "outputId": "e59e0f3c-e94d-4799-aa69-1a7f30e86c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running so far with 0 of 100: ID_CUAOY\n",
            "Running so far with 1 of 100: ID_OGSAY\n",
            "Running so far with 2 of 100: ID_TYHSA\n",
            "Running so far with 3 of 100: ID_CZXLD\n",
            "Running so far with 4 of 100: ID_ZJQUQ\n",
            "Running so far with 5 of 100: ID_HYSCV\n",
            "Running so far with 6 of 100: ID_DXHPF\n",
            "Running so far with 7 of 100: ID_GDFDN\n",
            "Running so far with 8 of 100: ID_UFAFI\n",
            "Running so far with 9 of 100: ID_KMBGG\n",
            "Running so far with 10 of 100: ID_GCHQJ\n",
            "Running so far with 11 of 100: ID_FBVXH\n",
            "Running so far with 12 of 100: ID_GFQXW\n",
            "Running so far with 13 of 100: ID_KQFSM\n",
            "Running so far with 14 of 100: ID_OTEWX\n",
            "Running so far with 15 of 100: ID_KTTZQ\n",
            "Running so far with 16 of 100: ID_DFFBJ\n",
            "Running so far with 17 of 100: ID_ZQLND\n",
            "Running so far with 18 of 100: ID_LXBDD\n",
            "Running so far with 19 of 100: ID_PWETS\n",
            "Running so far with 20 of 100: ID_VJVBS\n",
            "Running so far with 21 of 100: ID_OZCVT\n",
            "Running so far with 22 of 100: ID_HBKUL\n",
            "Running so far with 23 of 100: ID_ZVYUH\n",
            "Running so far with 24 of 100: ID_SHIKK\n",
            "Running so far with 25 of 100: ID_BZMKN\n",
            "Running so far with 26 of 100: ID_GWZRC\n",
            "Running so far with 27 of 100: ID_BMKRM\n",
            "Running so far with 28 of 100: ID_QDMBJ\n",
            "Running so far with 29 of 100: ID_LWSTJ\n",
            "Running so far with 30 of 100: ID_APFPK\n",
            "Running so far with 31 of 100: ID_NTHZR\n",
            "Running so far with 32 of 100: ID_UAHZM\n",
            "Running so far with 33 of 100: ID_UHJDN\n",
            "Running so far with 34 of 100: ID_FNAFQ\n",
            "Running so far with 35 of 100: ID_WRMNW\n",
            "Running so far with 36 of 100: ID_OMWIY\n",
            "Running so far with 37 of 100: ID_ZNYCZ\n",
            "Running so far with 38 of 100: ID_NCNYB\n",
            "Running so far with 39 of 100: ID_WKQEY\n",
            "Running so far with 40 of 100: ID_VLNLB\n",
            "Running so far with 41 of 100: ID_DGSSB\n",
            "Running so far with 42 of 100: ID_JADVZ\n",
            "Running so far with 43 of 100: ID_ILPTC\n",
            "Running so far with 44 of 100: ID_BGRFD\n",
            "Running so far with 45 of 100: ID_HDKYR\n",
            "Running so far with 46 of 100: ID_QAHFT\n",
            "Running so far with 47 of 100: ID_PESEJ\n",
            "Running so far with 48 of 100: ID_OFDGY\n",
            "Running so far with 49 of 100: ID_WGNEX\n",
            "Running so far with 50 of 100: ID_SIPNK\n",
            "Running so far with 51 of 100: ID_MXHUP\n",
            "Running so far with 52 of 100: ID_KBQBD\n",
            "Running so far with 53 of 100: ID_AYZDZ\n",
            "Running so far with 54 of 100: ID_GAWOX\n",
            "Running so far with 55 of 100: ID_DCOHP\n",
            "Running so far with 56 of 100: ID_RWISH\n",
            "Running so far with 57 of 100: ID_CQUKB\n",
            "Running so far with 58 of 100: ID_FFWID\n",
            "Running so far with 59 of 100: ID_XQHOA\n",
            "Running so far with 60 of 100: ID_PJSQE\n",
            "Running so far with 61 of 100: ID_EFYMF\n",
            "Running so far with 62 of 100: ID_QMQHY\n",
            "Running so far with 63 of 100: ID_QSQZO\n",
            "Running so far with 64 of 100: ID_HLPRM\n",
            "Running so far with 65 of 100: ID_WOBZV\n",
            "Running so far with 66 of 100: ID_QPFCH\n",
            "Running so far with 67 of 100: ID_CEPRG\n",
            "Running so far with 68 of 100: ID_SKCAI\n",
            "Running so far with 69 of 100: ID_JENNS\n",
            "Running so far with 70 of 100: ID_QSPEG\n",
            "Running so far with 71 of 100: ID_ZTHIV\n",
            "Running so far with 72 of 100: ID_HVSDS\n",
            "Running so far with 73 of 100: ID_BFBYN\n",
            "Running so far with 74 of 100: ID_EISIY\n",
            "Running so far with 75 of 100: ID_GCTMK\n",
            "Running so far with 76 of 100: ID_NIVMV\n",
            "Running so far with 77 of 100: ID_WZHQK\n",
            "Running so far with 78 of 100: ID_ZHSMO\n",
            "Running so far with 79 of 100: ID_RKTZL\n",
            "Running so far with 80 of 100: ID_PGEOO\n",
            "Running so far with 81 of 100: ID_VTRFF\n",
            "Running so far with 82 of 100: ID_CWEIL\n",
            "Running so far with 83 of 100: ID_WLSXB\n",
            "Running so far with 84 of 100: ID_VOVAB\n",
            "Running so far with 85 of 100: ID_XTMGG\n",
            "Running so far with 86 of 100: ID_ZHZRH\n",
            "Running so far with 87 of 100: ID_MVXJK\n",
            "Running so far with 88 of 100: ID_OPCIZ\n",
            "Running so far with 89 of 100: ID_LACGV\n",
            "Running so far with 90 of 100: ID_SCOBO\n",
            "Running so far with 91 of 100: ID_WQREZ\n",
            "Running so far with 92 of 100: ID_KYWMF\n",
            "Running so far with 93 of 100: ID_MURHB\n",
            "Running so far with 94 of 100: ID_MLUOW\n",
            "Running so far with 95 of 100: ID_AYCAI\n",
            "Running so far with 96 of 100: ID_CLEYN\n",
            "Running so far with 97 of 100: ID_BRIIW\n",
            "Running so far with 98 of 100: ID_SNZBL\n",
            "Running so far with 99 of 100: ID_KXLGG\n"
          ]
        }
      ],
      "source": [
        "df_online_test_predictions = llm_inference(model=model,\n",
        "                                     user_prompts=df_online_test_raw[['Master_Index','Prompt']],\n",
        "                                     system_prompt=instr_prompt2\n",
        "                                     )\n",
        "\n",
        "df_online_test_predictions.to_csv(f\"{BENCHMARK_PATH}/online_test_{model_name}_{run_timestamp}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aXiohEMncetk",
        "outputId": "5f6c4488-ecba-41ad-fc19-677e42b14ff1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_online_test_predictions\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Master_Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"ID_WLSXB\",\n          \"ID_AYZDZ\",\n          \"ID_QSPEG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clinician\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 96,\n        \"samples\": [\n          \"\\n\\nsummary a 20-year-old female brings with dry wheezing history history of being allergic to meat for 2 months history onset after eating beef on same side vital signs t - 36 p 40 rr18 o2 requirement give antihistamines oral loratadine or cyclosporin nebulizination\",\n          \"\\n\\nmanager thanks for bringing that to my attention managing diabetic wound with 21mmol l and 2mmol l is crucial given that the blood sugar levels need to be stabilized while the wound is healing it is essential to monitor vitals and document appropriately before treatment refer him promptly to a lower level hospital for further management diabetes education should be addressed first and this will focus on patient and caregiver advocacy understanding that patients with diabetes often need reassurance and ongoing support during health and wellbeing process infection prevention should be the priority consider adding an infectious disease team into management 1 stabilize vitals monitor vitals temperature blood pressure blood glucose hemoglobin a 10g dl full hemoglobin and creatinine perform an urgent blood test to rule out diabetic ketoacidosis wound infection se\",\n          \"\\n\\nsummary 38 year old man comes with cracked lips has severe dryness of skin lips everted crack in lip margin on skin surface has been rubbed or licking lips for a week there are also pain involved on touch due to trauma during morsal contact e g food consumption examination on palation there is dryness crusting from moisture evaporation vital signs normal temperature pulse \\u2013 weak at 86 min bp \\u2013 slightly low respiratory distress short temp normal respiratory effort spo2 of 98 at a slightly depressed level pain is the complaint on lips diagnosis lip stomatitis necrosis differential diagnosis chronic mouth dryness recurrent cold trauma infection poor adherence to dental therapy investigations skin swab to take culture from margins and assess the depth and area at entry site to check the location of\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_online_test_predictions"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-011a2c5a-289f-4f2b-b50e-0561c4859dcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Master_Index</th>\n",
              "      <th>Clinician</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_CUAOY</td>\n",
              "      <td>\\n\\nsummary a 25 year old female presents to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_OGSAY</td>\n",
              "      <td>\\n\\nsummary patient is a three year old male w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_TYHSA</td>\n",
              "      <td>\\n\\nsummary child Health the child has a weakn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_CZXLD</td>\n",
              "      <td>\\n\\nas a community nurse working in a dispensa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_ZJQUQ</td>\n",
              "      <td>\\n\\ngood assessment by the patient the patient...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-011a2c5a-289f-4f2b-b50e-0561c4859dcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-011a2c5a-289f-4f2b-b50e-0561c4859dcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-011a2c5a-289f-4f2b-b50e-0561c4859dcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ef493031-d14a-417c-9852-f0c85f140dbf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef493031-d14a-417c-9852-f0c85f140dbf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ef493031-d14a-417c-9852-f0c85f140dbf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  Master_Index                                          Clinician\n",
              "0     ID_CUAOY  \\n\\nsummary a 25 year old female presents to t...\n",
              "1     ID_OGSAY  \\n\\nsummary patient is a three year old male w...\n",
              "2     ID_TYHSA  \\n\\nsummary child Health the child has a weakn...\n",
              "3     ID_CZXLD  \\n\\nas a community nurse working in a dispensa...\n",
              "4     ID_ZJQUQ  \\n\\ngood assessment by the patient the patient..."
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_online_test_predictions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUEPI54Rd2kk",
        "outputId": "898efaa9-5515-498a-ed64-0bb222a8e793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\") # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GNOMAieeCcL"
      },
      "outputs": [],
      "source": [
        "prompt_test_message = 'i am a nurse with 18 years of experience in general nursing working in a sub county hospitals and nursing homes in uasin gishu county in kenya a 4 year old child presents to the emergency department with second degree burns on the forearm after accidentally touching a hot stove the child was playing in the kitchen when they reached out to touch the stove the burns cover about 5 of the total body surface area the child is alert and crying with redness blisters and swelling on the affected area the burns appear to be superficial to moderate in severity the child is in mild pain and there is no indication of airway or breathing distress no other injuries are noted questions 1 what is the immediate treatment protocol for second degree burns in paediatric patients 2 should any tetanus prophylaxis be considered in this case 3 what follow up care should be recommended for burn healing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_0_dpe0eNLi",
        "outputId": "06543d88-fbe4-4153-9e1a-80e5095fc45a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on your scenario as a 28 year old nurse with 18 years of experience in general nursing working in a sub county hospitals and nursing homes in uasin gishu county in kenya i'll provide guidance on the immediate treatment protocol for second degree burns in paediatric patients along with suggestions on follow up care and considerations regarding tetanus prophylaxis 1 immediate treatment protocol for second degree burns in paediatric patients burn assessment carefully assess the child's burns to identify severity using the following criteria • superficial burns limited to the epidermis (outer layer of skin) • moderate burns damage extends to the dermis (middle layer of skin\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt_test_message},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k6NQoogeTki",
        "outputId": "3f26e9bd-f189-411a-bed0-434dce8606c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 2.5G\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 4.44 out of 12.67 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:01<00:00, 15.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving software-together/model-v2-gguf/pytorch_model.bin...\n",
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m', 'q8_0', 'q5_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at software-together/model-v2-gguf into f16 GGUF format.\n",
            "The output location will be /content/software-together/model-v2-gguf/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: model-v2-gguf\n",
            "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {32}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {2048, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 131072\n",
            "INFO:hf-to-gguf:gguf: embedding length = 2048\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128004\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 July 2024\" %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content'] %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\n",
            "\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\n",
            "\n",
            "\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\n",
            "\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\n",
            "\n",
            "\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\n",
            "\n",
            "\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\n",
            "\n",
            "\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content'] %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\n",
            "\n",
            "\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\n",
            "\n",
            "\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\n",
            "\n",
            "\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\n",
            "\n",
            "\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}\n",
            "{%- endif %}\n",
            "\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/software-together/model-v2-gguf/unsloth.F16.gguf: n_tensors = 147, total_size = 2.5G\n",
            "Writing: 100%|██████████| 2.47G/2.47G [00:38<00:00, 63.7Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/software-together/model-v2-gguf/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/software-together/model-v2-gguf/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 5456 (cc74d5be)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/software-together/model-v2-gguf/unsloth.F16.gguf' to '/content/software-together/model-v2-gguf/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 28 key-value pairs and 147 tensors from /content/software-together/model-v2-gguf/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Model v2 Gguf\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 1.2B\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 16\n",
            "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 64\n",
            "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - type  f32:   34 tensors\n",
            "llama_model_loader: - type  f16:  113 tensors\n",
            "[   1/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   2/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   3/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =    f16, converting to q6_K .. size =   501.00 MiB ->   205.49 MiB\n",
            "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[   5/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   7/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   8/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  10/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  12/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  14/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  16/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  17/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  19/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  21/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  23/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  25/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  26/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  28/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  30/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  32/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  34/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  35/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  37/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  39/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  41/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  43/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  44/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  46/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  48/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  50/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  52/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  53/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  55/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  57/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  59/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  61/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  62/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  64/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  66/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  68/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  70/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  71/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  73/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  75/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  77/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  79/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  80/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  82/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  84/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  86/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  88/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  89/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  91/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  93/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  95/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  97/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  98/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 100/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 102/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 104/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 106/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 107/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 109/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 111/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 113/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 115/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 116/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 118/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 120/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 122/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 124/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 125/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 127/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 129/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 131/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 133/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 134/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 136/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 138/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 140/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 142/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 143/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 145/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 147/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "llama_model_quantize_impl: model size  =  2357.26 MB\n",
            "llama_model_quantize_impl: quant size  =   762.81 MB\n",
            "\n",
            "main: quantize time = 120780.52 ms\n",
            "main:    total time = 120780.52 ms\n",
            "Unsloth: Conversion completed! Output location: /content/software-together/model-v2-gguf/unsloth.Q4_K_M.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q8_0. This might take 20 minutes...\n",
            "main: build = 5456 (cc74d5be)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/software-together/model-v2-gguf/unsloth.F16.gguf' to '/content/software-together/model-v2-gguf/unsloth.Q8_0.gguf' as Q8_0 using 4 threads\n",
            "llama_model_loader: loaded meta data with 28 key-value pairs and 147 tensors from /content/software-together/model-v2-gguf/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Model v2 Gguf\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 1.2B\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 16\n",
            "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 64\n",
            "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - type  f32:   34 tensors\n",
            "llama_model_loader: - type  f16:  113 tensors\n",
            "[   1/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   2/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   3/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =    f16, converting to q8_0 .. size =   501.00 MiB ->   266.16 MiB\n",
            "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[   5/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[   7/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[   8/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  10/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  12/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  14/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  16/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  17/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  19/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  21/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  23/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  25/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  26/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  28/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  30/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  32/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  34/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  35/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  37/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  39/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  41/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  43/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  44/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  46/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  48/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  50/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  52/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  53/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  55/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  57/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  59/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  61/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  62/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  64/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  66/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  68/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  70/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  71/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  73/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  75/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  77/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  79/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  80/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  82/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  84/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  86/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  88/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  89/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  91/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  93/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  95/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  97/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  98/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 100/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 102/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 104/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 106/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 107/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 109/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 111/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 113/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 115/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 116/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 118/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 120/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 122/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 124/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 125/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 127/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 129/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 131/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 133/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 134/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 136/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 138/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 140/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 142/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 143/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 145/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 147/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "llama_model_quantize_impl: model size  =  2357.26 MB\n",
            "llama_model_quantize_impl: quant size  =  1252.41 MB\n",
            "\n",
            "main: quantize time = 31318.94 ms\n",
            "main:    total time = 31318.94 ms\n",
            "Unsloth: Conversion completed! Output location: /content/software-together/model-v2-gguf/unsloth.Q8_0.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q5_k_m. This might take 20 minutes...\n",
            "main: build = 5456 (cc74d5be)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/software-together/model-v2-gguf/unsloth.F16.gguf' to '/content/software-together/model-v2-gguf/unsloth.Q5_K_M.gguf' as Q5_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 28 key-value pairs and 147 tensors from /content/software-together/model-v2-gguf/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Model v2 Gguf\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 1.2B\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 16\n",
            "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 64\n",
            "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - type  f32:   34 tensors\n",
            "llama_model_loader: - type  f16:  113 tensors\n",
            "[   1/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   2/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   3/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =    f16, converting to q6_K .. size =   501.00 MiB ->   205.49 MiB\n",
            "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[   5/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[   7/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[   8/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  10/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  12/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  14/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  16/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  17/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  19/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  21/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  23/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  25/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  26/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  28/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  30/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  32/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  34/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  35/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  37/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  39/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  41/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  43/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  44/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  46/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  48/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  50/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  52/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  53/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  55/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  57/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  59/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  61/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  62/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  64/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  66/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  68/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  70/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  71/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  73/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  75/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  77/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  79/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  80/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  82/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  84/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  86/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  88/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  89/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  91/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  93/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  95/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  97/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  98/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 100/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 102/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 104/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 106/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 107/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 109/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 111/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 113/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 115/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 116/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 118/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 120/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 122/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 124/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 125/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 127/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 129/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 131/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 133/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 134/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 136/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 138/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 140/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 142/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 143/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 145/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 147/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "llama_model_quantize_impl: model size  =  2357.26 MB\n",
            "llama_model_quantize_impl: quant size  =   861.81 MB\n",
            "\n",
            "main: quantize time = 104935.20 ms\n",
            "main:    total time = 104935.20 ms\n",
            "Unsloth: Conversion completed! Output location: /content/software-together/model-v2-gguf/unsloth.Q5_K_M.gguf\n",
            "Unsloth: Saved Ollama Modelfile to software-together/model-v2-gguf/Modelfile\n"
          ]
        }
      ],
      "source": [
        "# Merge to 16bit\n",
        "#if True: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "#if True: model.push_to_hub_merged(f\"{model_name}-16bit\", tokenizer, save_method = \"merged_16bit\", token = token)\n",
        "\n",
        "if True:\n",
        "    model.save_pretrained_gguf(\n",
        "    #model.push_to_hub_gguf(\n",
        "        f\"{model_name}-gguf\",\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        #token = token,\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "030143feaa764f8699382ed77fa64726": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06a2c21f7bca4cf3b0f5a9a944302068": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0777c7f48ab048e7a3d59d62def95d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c5ec705dcb4b9582a8a1569ee27636",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9a79d2679a6406e8cda54eee6811048",
            "value": 239
          }
        },
        "08e66b003a5b4a1c97ed06f34e98d371": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c8ecbba73d84886a9b4e7ad9d12e317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1022bc51f3f0465597992514df0a7f55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b4a9d97b6740cd85b6e0cf619ac077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "148b1f5171f24a0082de921b963286d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16fc24644d9c4f59b95fd38912281f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624dbc94f5ad4eca8bb35fe5ba322691",
            "placeholder": "​",
            "style": "IPY_MODEL_fc45fb0df04644049fd5302a46699938",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1b04a2f923c545a1b1507812ed784f27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da2631b0c14493bb8cddc1f1dc6c243": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e512981e44a40008ee921612271bfc4",
            "placeholder": "​",
            "style": "IPY_MODEL_2e6c3259054e4f028079d516316fde8a",
            "value": " 54.7k/54.7k [00:00&lt;00:00, 1.35MB/s]"
          }
        },
        "1f353c9c9ccc49bb9232dc9365e3a98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fde00c5a29345dd96753404c7eac2d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21da7ba104414ce69b51e0bc0faac36a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22511cc6d54d4a0a8252a6b3e91e8cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a4739fb7a54ecc9f6e9ebecd68861b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d21c25a10b646c5b129a4ad7513e719",
            "placeholder": "​",
            "style": "IPY_MODEL_ec20538d04e74678bcbc8e9e07a42ef3",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
          }
        },
        "28daa403a9004d7990729095c3c86ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28eb1248b4fe4020937c977333d4a47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b8f51849dbf4fc6a5f72668bd790dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1a3c0d06a54a6995d94c42d4ec3990": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6c3259054e4f028079d516316fde8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "350c0295cee84d26b9ec566a75238ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3629d2fa15fd4a29870ae8979a76cff6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c2b055fa7b14568b0d899246088ea17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c4702d772c74902966728b4979b473e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24a4739fb7a54ecc9f6e9ebecd68861b",
              "IPY_MODEL_bf37c7ae1dcf482592d29bcbcfa4433a",
              "IPY_MODEL_a9b220c1996445eea3e0c716105f23af"
            ],
            "layout": "IPY_MODEL_2b8f51849dbf4fc6a5f72668bd790dd0"
          }
        },
        "456ab4165b5f40a882f5db5e47c5b13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3629d2fa15fd4a29870ae8979a76cff6",
            "placeholder": "​",
            "style": "IPY_MODEL_06a2c21f7bca4cf3b0f5a9a944302068",
            "value": "tokenizer.json: 100%"
          }
        },
        "4689f7b1ad44469ca02e73e01cdd3dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ae3ed1b6a5e432ebf412638354e0174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bc4bd2d65a74359b74bcf1f2ea58f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50e67a287d3b4ddd8a10daaa7a0caf09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16fc24644d9c4f59b95fd38912281f3c",
              "IPY_MODEL_84d35236c71549ef94405fdabad742f0",
              "IPY_MODEL_c986a538f1a34408acbb4540a2aa9ccc"
            ],
            "layout": "IPY_MODEL_f29ff94f3ba041f69d28a69aa43207af"
          }
        },
        "52334b5816f84059a4df44d519b427d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53190e4d69cd47bf9be2550b356211ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5591bdc5056b413ea6d03561dd781ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5824e2e912e7469990e9ab7fe17cdc18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0108ae173c24536b3c35e01b693e03b",
            "placeholder": "​",
            "style": "IPY_MODEL_12b4a9d97b6740cd85b6e0cf619ac077",
            "value": " 18/18 [00:01&lt;00:00, 12.23 examples/s]"
          }
        },
        "591c2a03c9ef4797b81fd573bbac337b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c037846b19743f896b6b4b61f01d721": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d21c25a10b646c5b129a4ad7513e719": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5feeeca2b5d84c7b816e8ca69f9fbf19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61aceaf4a0004681beb349fbaedf0fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624dbc94f5ad4eca8bb35fe5ba322691": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63c7ae9f2adf494a99fdcb3afad21a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64534362c7db448b9345e23d7a0c3f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f92c590a57324ed8a4a4c4b27379a3c9",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_591c2a03c9ef4797b81fd573bbac337b",
            "value": 234
          }
        },
        "6b0a1164d4434cb9b22e5cc339e89399": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b206a319ec04f1a9f28e3e6d45cc224": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d880f8aa13c4563978f137b53afd241": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e66b003a5b4a1c97ed06f34e98d371",
            "placeholder": "​",
            "style": "IPY_MODEL_1f353c9c9ccc49bb9232dc9365e3a98a",
            "value": " 234/234 [00:00&lt;00:00, 8.69kB/s]"
          }
        },
        "7127e4e7b0af4cb6a84a404cb192cb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21da7ba104414ce69b51e0bc0faac36a",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4689f7b1ad44469ca02e73e01cdd3dfb",
            "value": 2471645373
          }
        },
        "79ba63b23b6f407f8300e8865e1fb86e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7deb31e3f56e47a8a02225952c0eab84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b04a2f923c545a1b1507812ed784f27",
            "placeholder": "​",
            "style": "IPY_MODEL_0c8ecbba73d84886a9b4e7ad9d12e317",
            "value": " 17.2M/17.2M [00:00&lt;00:00, 35.5MB/s]"
          }
        },
        "7ebe07334cf54215acf77d2ff1146e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c2b055fa7b14568b0d899246088ea17",
            "placeholder": "​",
            "style": "IPY_MODEL_f50601c8e37e4ae18ee1472aff5453b7",
            "value": "model.safetensors: 100%"
          }
        },
        "7ee4f567699646da8e3daa8accc9d367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82761c9846854ea1a0b53982899fa5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd82f413ee34d13840527c87444e255",
            "placeholder": "​",
            "style": "IPY_MODEL_5591bdc5056b413ea6d03561dd781ffa",
            "value": " 2.47G/2.47G [00:16&lt;00:00, 350MB/s]"
          }
        },
        "84d35236c71549ef94405fdabad742f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1022bc51f3f0465597992514df0a7f55",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf950cf057fa428ea8d16e1395fce44e",
            "value": 454
          }
        },
        "85dad603d3804acca9cc28e1374ead63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c9e1b3231c4210951cf17accbced58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87f1f03e98c54b9696ec8a1d08dc612f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_148b1f5171f24a0082de921b963286d2",
            "max": 54674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63c7ae9f2adf494a99fdcb3afad21a96",
            "value": 54674
          }
        },
        "8e512981e44a40008ee921612271bfc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9042ac43ba094748b7e5c6cf7ac64bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_905aa4183abb4df0972a6b04f489becd",
            "placeholder": "​",
            "style": "IPY_MODEL_4bc4bd2d65a74359b74bcf1f2ea58f2b",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
          }
        },
        "905aa4183abb4df0972a6b04f489becd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9789a31798824be98ade4e68144a1b59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9908245dc72d43388554b506d956a97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9789a31798824be98ade4e68144a1b59",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc66827777e74254a5fb62f2197d2f9c",
            "value": 18
          }
        },
        "9a1eed9965804dc4966d31f010ffc43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53190e4d69cd47bf9be2550b356211ef",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ae3ed1b6a5e432ebf412638354e0174",
            "value": 17209920
          }
        },
        "9a6bdbca471046348bea38146b78ddba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ad866b3cffe4ef597f48c0dc5c13e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fde00c5a29345dd96753404c7eac2d5",
            "max": 1027676737,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2a082097e4e42e699e0d8ca75db0452",
            "value": 1027676639
          }
        },
        "9bf2b01fc66346758436765a70f7cdc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9a79d2679a6406e8cda54eee6811048": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9b220c1996445eea3e0c716105f23af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef137c61bec74e9b91d38bbc12f320c9",
            "placeholder": "​",
            "style": "IPY_MODEL_e63defbe745441cbbd1ddb3c40dffd36",
            "value": " 1376/1376 [00:06&lt;00:00, 245.94 examples/s]"
          }
        },
        "ab2dca7bb9a249ccb75423786d8c50fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ebe07334cf54215acf77d2ff1146e8f",
              "IPY_MODEL_9ad866b3cffe4ef597f48c0dc5c13e22",
              "IPY_MODEL_c9f725be622a4f148b122a4d769845a1"
            ],
            "layout": "IPY_MODEL_030143feaa764f8699382ed77fa64726"
          }
        },
        "adfba968acae4276b55a7699aa42ce1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aee6df096c94467fb500e2094f6606a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28daa403a9004d7990729095c3c86ad5",
            "placeholder": "​",
            "style": "IPY_MODEL_adfba968acae4276b55a7699aa42ce1c",
            "value": " 239/239 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "b0108ae173c24536b3c35e01b693e03b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b109e5c94a164520bcc6e1836cfc214b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e531e3fbe0b64a46a4adf5d9d04fe884",
              "IPY_MODEL_87f1f03e98c54b9696ec8a1d08dc612f",
              "IPY_MODEL_1da2631b0c14493bb8cddc1f1dc6c243"
            ],
            "layout": "IPY_MODEL_85dad603d3804acca9cc28e1374ead63"
          }
        },
        "b17fab78ea3941258d9b75d9cc0512a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b18d1f1efa5849bdb1ae524e0cfcabca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d3aad420344dcab88701bc086c087f",
            "placeholder": "​",
            "style": "IPY_MODEL_9bf2b01fc66346758436765a70f7cdc2",
            "value": "model.safetensors: 100%"
          }
        },
        "bf37c7ae1dcf482592d29bcbcfa4433a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_350c0295cee84d26b9ec566a75238ff1",
            "max": 1376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ee4f567699646da8e3daa8accc9d367",
            "value": 1376
          }
        },
        "bffb58d39d474c5092b5a63fe99bb83d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c986a538f1a34408acbb4540a2aa9ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c037846b19743f896b6b4b61f01d721",
            "placeholder": "​",
            "style": "IPY_MODEL_6b0a1164d4434cb9b22e5cc339e89399",
            "value": " 454/454 [00:00&lt;00:00, 14.1kB/s]"
          }
        },
        "c9f725be622a4f148b122a4d769845a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17fab78ea3941258d9b75d9cc0512a4",
            "placeholder": "​",
            "style": "IPY_MODEL_86c9e1b3231c4210951cf17accbced58",
            "value": " 1.03G/1.03G [00:11&lt;00:00, 273MB/s]"
          }
        },
        "cbd82f413ee34d13840527c87444e255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf950cf057fa428ea8d16e1395fce44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1f16ed10f104288b5003e7cbde97655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8f4d9eb48a64a33a51cb0562318de69",
              "IPY_MODEL_0777c7f48ab048e7a3d59d62def95d7b",
              "IPY_MODEL_aee6df096c94467fb500e2094f6606a1"
            ],
            "layout": "IPY_MODEL_bffb58d39d474c5092b5a63fe99bb83d"
          }
        },
        "d2a082097e4e42e699e0d8ca75db0452": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7532021e92748f5805395af7312f5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9042ac43ba094748b7e5c6cf7ac64bd5",
              "IPY_MODEL_9908245dc72d43388554b506d956a97d",
              "IPY_MODEL_5824e2e912e7469990e9ab7fe17cdc18"
            ],
            "layout": "IPY_MODEL_f7f0aa5872a44350abd5c635c415adb5"
          }
        },
        "e3d3aad420344dcab88701bc086c087f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c5ec705dcb4b9582a8a1569ee27636": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e531e3fbe0b64a46a4adf5d9d04fe884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b206a319ec04f1a9f28e3e6d45cc224",
            "placeholder": "​",
            "style": "IPY_MODEL_28eb1248b4fe4020937c977333d4a47a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e63defbe745441cbbd1ddb3c40dffd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec20538d04e74678bcbc8e9e07a42ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed261e7d192445b0b89a0400b4b6bdd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_456ab4165b5f40a882f5db5e47c5b13e",
              "IPY_MODEL_9a1eed9965804dc4966d31f010ffc43b",
              "IPY_MODEL_7deb31e3f56e47a8a02225952c0eab84"
            ],
            "layout": "IPY_MODEL_52334b5816f84059a4df44d519b427d3"
          }
        },
        "ee0bafd2bab34790a66bc5642260b7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61aceaf4a0004681beb349fbaedf0fe0",
            "placeholder": "​",
            "style": "IPY_MODEL_9a6bdbca471046348bea38146b78ddba",
            "value": "generation_config.json: 100%"
          }
        },
        "ef137c61bec74e9b91d38bbc12f320c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f251b4a0da9a430cb91739b2ae7d99a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b18d1f1efa5849bdb1ae524e0cfcabca",
              "IPY_MODEL_7127e4e7b0af4cb6a84a404cb192cb6a",
              "IPY_MODEL_82761c9846854ea1a0b53982899fa5a1"
            ],
            "layout": "IPY_MODEL_79ba63b23b6f407f8300e8865e1fb86e"
          }
        },
        "f29ff94f3ba041f69d28a69aa43207af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f50601c8e37e4ae18ee1472aff5453b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7f0aa5872a44350abd5c635c415adb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ae0ffc4ce149a8bca50951437695a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee0bafd2bab34790a66bc5642260b7b9",
              "IPY_MODEL_64534362c7db448b9345e23d7a0c3f75",
              "IPY_MODEL_6d880f8aa13c4563978f137b53afd241"
            ],
            "layout": "IPY_MODEL_22511cc6d54d4a0a8252a6b3e91e8cf1"
          }
        },
        "f8f4d9eb48a64a33a51cb0562318de69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1a3c0d06a54a6995d94c42d4ec3990",
            "placeholder": "​",
            "style": "IPY_MODEL_5feeeca2b5d84c7b816e8ca69f9fbf19",
            "value": "generation_config.json: 100%"
          }
        },
        "f92c590a57324ed8a4a4c4b27379a3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc45fb0df04644049fd5302a46699938": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc66827777e74254a5fb62f2197d2f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
